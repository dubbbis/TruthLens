{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Final Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run these to install\n",
    "\n",
    "pip install chromadb wikipedia-api requests spacy textblob scikit-learn nltk         \\\n",
    "python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import spacy\n",
    "import wikipediaapi\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Load ChromaDB + Check Google Fact API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\newpc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Wikipedia summary for 'COVID-19':\n",
      "Coronavirus disease 2019 (COVID-19) is a contagiou...\n",
      "‚úÖ Wikipedia API initialized successfully!\n",
      "‚úÖ Wikipedia API initialized successfully!\n",
      "‚úÖ ChromaDB & External APIs initialized!\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Initialize NLP Models\n",
    "nltk.download(\"punkt\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# ‚úÖ Initialize ChromaDB\n",
    "CHROMA_DB_PATH = \"../chroma_db\"\n",
    "client = chromadb.PersistentClient(path=CHROMA_DB_PATH)\n",
    "collection = client.get_collection(\"news_articles\")\n",
    "\n",
    "# ‚úÖ Define user agent properly for Wikipedia API\n",
    "WIKI_USER_AGENT = \"FakeBuster/1.0 (contact: maxwellcranston@gmail.com)\"\n",
    "\n",
    "# ‚úÖ Initialize Wikipedia API with User-Agent\n",
    "wiki = wikipediaapi.Wikipedia(\n",
    "    language='en',\n",
    "    user_agent=WIKI_USER_AGENT  # Pass user-agent correctly\n",
    ")\n",
    "\n",
    "# ‚úÖ Test Wikipedia Query\n",
    "page = wiki.page(\"COVID-19\")\n",
    "\n",
    "print(f\"üîç Wikipedia summary for 'COVID-19':\\n{page.summary[:50]}...\")  # Print first 500 chars\n",
    "\n",
    "print(\"‚úÖ Wikipedia API initialized successfully!\")\n",
    "\n",
    "\n",
    "print(\"‚úÖ Wikipedia API initialized successfully!\")\n",
    "\n",
    "# ‚úÖ Google Fact Check API Key (Get from Google Fact Check Tools API)\n",
    "GOOGLE_FACTCHECK_API_KEY = \"AIzaSyAP0d1Ma_yn4TVDXuuGljtJZSdC08P1Y_U\"\n",
    "\n",
    "print(\"‚úÖ ChromaDB & External APIs initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition (NER) for Context Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Retrieved 171 articles from ChromaDB.\n",
      "‚úÖ Named Entity Recognition (NER) completed!\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Function to extract named entities\n",
    "def extract_entities(text):\n",
    "    \"\"\"Extract key named entities (names, locations, organizations) from text.\"\"\"\n",
    "    doc = nlp(text)\n",
    "    entities = {ent.text for ent in doc.ents if ent.label_ in {\"PERSON\", \"ORG\", \"GPE\"}}\n",
    "    return list(entities)\n",
    "\n",
    "# ‚úÖ Fetch Articles from ChromaDB\n",
    "articles = collection.get()\n",
    "print(f\"‚úÖ Retrieved {len(articles['documents'])} articles from ChromaDB.\")\n",
    "\n",
    "# ‚úÖ Extract Named Entities from each article\n",
    "article_entities = {}\n",
    "for i, doc in enumerate(articles[\"documents\"]):\n",
    "    entities = extract_entities(doc)\n",
    "    article_entities[articles[\"ids\"][i]] = entities\n",
    "\n",
    "print(\"‚úÖ Named Entity Recognition (NER) completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve and Fetch steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Retrieve: Related Articles\n",
    "- Fetch Additional Fact-Checking Data (Google Fact Check API and Wikipedia )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: We are saving to memory and not committing to the ChromaDB yet, only after Ling analysis is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:39<00:00, 39.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed 1 article(s) with related context & fact-checking data!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# ‚úÖ Expand Articles with Related Context + Fact-Checking\\nexpanded_articles = {}\\nfor article_id, entities in tqdm(article_entities.items()):\\n    related_content = []\\n    fact_check_data = []\\n\\n    for entity in entities:\\n        related_articles = search_related_articles(entity)\\n        fact_check_results = get_factcheck_results(entity)\\n        wikipedia_summary = get_wikipedia_summary(entity)\\n\\n        related_content.extend(related_articles)  # This may contain lists\\n        fact_check_data.append(f\"Fact-Check: {fact_check_results}\\nWikipedia: {wikipedia_summary}\")\\n\\n    # ‚úÖ Fix: Convert all related content items to strings before joining\\n    expanded_articles[article_id] = (\\n        articles[\"documents\"][articles[\"ids\"].index(article_id)]\\n        + \"\\n\\nRelated Content:\\n\" + \"\\n\".join([str(item) for item in related_content])\\n        + \"\\n\\nFact-Checking Data:\\n\" + \"\\n\".join(fact_check_data)\\n    )\\n\\nprint(\"‚úÖ Articles enriched with related context & fact-checking data!\")\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ‚úÖ Toggle for Quick Testing (Set to True for processing only 1 article)\n",
    "DEBUG_MODE = True  # Change to False for full processing\n",
    "\n",
    "# ‚úÖ Function to search ChromaDB using named entities\n",
    "def search_related_articles(entity):\n",
    "    \"\"\"Retrieve related articles using entity search.\"\"\"\n",
    "    results = collection.query(query_texts=[entity], n_results=3)  # Adjust results as needed\n",
    "    return results[\"documents\"]\n",
    "\n",
    "# ‚úÖ Function to fetch Google Fact Check API results with timeout & logging\n",
    "def get_factcheck_results(query, timeout=5):\n",
    "    \"\"\"Retrieve fact-check results from Google's Fact Check API with timeout handling.\"\"\"\n",
    "    url = f\"https://factchecktools.googleapis.com/v1alpha1/claims:search?query={query}&key={GOOGLE_FACTCHECK_API_KEY}\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=timeout)\n",
    "        response.raise_for_status()  # Raise an error for bad responses\n",
    "        data = response.json().get(\"claims\", [])\n",
    "        return [claim[\"text\"] for claim in data] if data else [\"No fact-checks found.\"]\n",
    "    except requests.exceptions.Timeout:\n",
    "        return [\"‚ö†Ô∏è Fact-check API timed out.\"]\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return [f\"‚ö†Ô∏è Fact-check API error: {str(e)}\"]\n",
    "\n",
    "# ‚úÖ Function to fetch Wikipedia summary with error handling\n",
    "def get_wikipedia_summary(entity):\n",
    "    \"\"\"Retrieve a brief Wikipedia summary for an entity if available.\"\"\"\n",
    "    try:\n",
    "        page = wiki.page(entity)\n",
    "        return page.summary if page.exists() else \"No Wikipedia data found.\"\n",
    "    except Exception as e:\n",
    "        return f\"‚ö†Ô∏è Wikipedia fetch error: {str(e)}\"\n",
    "\n",
    "\n",
    "\n",
    "# ‚úÖ Expand Articles with Related Context + Fact-Checking\n",
    "expanded_articles = {}\n",
    "\n",
    "# ‚úÖ Limit processing to 1 article when in DEBUG mode\n",
    "article_items = list(article_entities.items())  # Convert dict to list for indexing\n",
    "if DEBUG_MODE:\n",
    "    article_items = article_items[:1]  # Only process the first article\n",
    "\n",
    "for article_id, entities in tqdm(article_items):  # Now uses `article_items`\n",
    "    related_content = []\n",
    "    fact_check_data = []\n",
    "\n",
    "    for entity in entities:\n",
    "        related_articles = search_related_articles(entity)\n",
    "        fact_check_results = get_factcheck_results(entity)\n",
    "        wikipedia_summary = get_wikipedia_summary(entity)\n",
    "\n",
    "        related_content.extend(related_articles)  # This may contain lists\n",
    "        fact_check_data.append(f\"Fact-Check: {fact_check_results}\\nWikipedia: {wikipedia_summary}\")\n",
    "\n",
    "    # ‚úÖ Fix: Convert all related content items to strings before joining\n",
    "    expanded_articles[article_id] = (\n",
    "        articles[\"documents\"][articles[\"ids\"].index(article_id)]\n",
    "        + \"\\n\\nRelated Content:\\n\" + \"\\n\".join([str(item) for item in related_content])\n",
    "        + \"\\n\\nFact-Checking Data:\\n\" + \"\\n\".join(fact_check_data)\n",
    "    )\n",
    "\n",
    "print(f\"‚úÖ Processed {len(expanded_articles)} article(s) with related context & fact-checking data!\")\n",
    "\n",
    "'''\n",
    "# ‚úÖ Expand Articles with Related Context + Fact-Checking\n",
    "expanded_articles = {}\n",
    "for article_id, entities in tqdm(article_entities.items()):\n",
    "    related_content = []\n",
    "    fact_check_data = []\n",
    "\n",
    "    for entity in entities:\n",
    "        related_articles = search_related_articles(entity)\n",
    "        fact_check_results = get_factcheck_results(entity)\n",
    "        wikipedia_summary = get_wikipedia_summary(entity)\n",
    "\n",
    "        related_content.extend(related_articles)  # This may contain lists\n",
    "        fact_check_data.append(f\"Fact-Check: {fact_check_results}\\nWikipedia: {wikipedia_summary}\")\n",
    "\n",
    "    # ‚úÖ Fix: Convert all related content items to strings before joining\n",
    "    expanded_articles[article_id] = (\n",
    "        articles[\"documents\"][articles[\"ids\"].index(article_id)]\n",
    "        + \"\\n\\nRelated Content:\\n\" + \"\\n\".join([str(item) for item in related_content])\n",
    "        + \"\\n\\nFact-Checking Data:\\n\" + \"\\n\".join(fact_check_data)\n",
    "    )\n",
    "\n",
    "print(\"‚úÖ Articles enriched with related context & fact-checking data!\")\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linguistic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç **Test Entry Preview Before DB Commit** üîç\n",
      "üìå **Article ID:** https://newsone.com/5939034/presidents-are-judged-by-history-through-the-lens-of-morality/\n",
      "üìú **Content (Snippet):** A statue of Abraham Lincoln, the 16th president of the United States, sits in the Lincoln Memorial in Washington. Historians consistently have given Lincoln, the Great Emancipator, their highest rating because of his leadership during the Civil War. Jakub Porzycki/NurPhoto via Getty Images\n",
      "\n",
      "What will be former President Joe Biden‚Äôs legacy? How will Americans in the future consider his four years in office?\n",
      "\n",
      "Every American president lands in the history books. And historians‚Äô assessments of their...\n",
      "üìä **Linguistic Analysis:**\n",
      "   - TF-IDF Outliers: ['2021', 'surveys', 'historians', 'president', 'presidents']\n",
      "   - Sentiment Polarity: 0.11306499148476427\n",
      "   - Sentiment Subjectivity: 0.4317448386062364\n",
      "   - Grammar Errors: 128707\n",
      "   - Sentence Count: 3856\n",
      "   - Entity Count: 12364\n",
      "   - Text Length: 108308\n",
      "\n",
      "üõ†Ô∏è **Confirm before committing to ChromaDB!**\n",
      "‚úÖ Linguistic analysis completed for 1 articles!\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ TF-IDF Outlier Analysis\n",
    "def tfidf_outliers(texts, top_n=5):\n",
    "    \"\"\"Finds top N high-TF-IDF words per article.\"\"\"\n",
    "    texts = [text if isinstance(text, str) else \"\" for text in texts]\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "    tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    outlier_words = []\n",
    "    for row in tfidf_matrix:\n",
    "        scores = row.toarray()[0]\n",
    "        top_indices = scores.argsort()[-top_n:]\n",
    "        outlier_words.append([feature_names[i] for i in top_indices])\n",
    "\n",
    "    return outlier_words\n",
    "\n",
    "# ‚úÖ Sentiment Analysis\n",
    "def sentiment_analysis(text):\n",
    "    \"\"\"Detects sentiment polarity and emotional words.\"\"\"\n",
    "    analysis = TextBlob(text)\n",
    "    return {\"polarity\": analysis.sentiment.polarity, \"subjectivity\": analysis.sentiment.subjectivity}\n",
    "\n",
    "# ‚úÖ Grammar & Readability Analysis\n",
    "def grammar_analysis(text):\n",
    "    \"\"\"Analyzes grammatical complexity and readability.\"\"\"\n",
    "    doc = nlp(text)\n",
    "    errors = sum(1 for token in doc if token.is_oov)  # Out-of-vocabulary words\n",
    "    sentences = len(list(doc.sents))\n",
    "    return {\"grammar_errors\": errors, \"sentence_count\": sentences}\n",
    "\n",
    "# ‚úÖ Named Entity Density Analysis\n",
    "def named_entity_density(text):\n",
    "    \"\"\"Measures how many entities exist in a given text.\"\"\"\n",
    "    doc = nlp(text)\n",
    "    return {\"entity_count\": len(doc.ents), \"text_length\": len(text.split())}\n",
    "\n",
    "# ‚úÖ Processed Articles with Linguistic Analysis\n",
    "final_articles = {}\n",
    "\n",
    "for article_id, enriched_text in expanded_articles.items():\n",
    "    # ‚úÖ Run Linguistic Analysis\n",
    "    tfidf_outliers_list = tfidf_outliers([enriched_text])[0]\n",
    "    sentiment = sentiment_analysis(enriched_text)\n",
    "    grammar = grammar_analysis(enriched_text)\n",
    "    entity_density = named_entity_density(enriched_text)\n",
    "\n",
    "    # ‚úÖ Merge with previous enrichment (RAG context + Fact-checking + Linguistics)\n",
    "    final_articles[article_id] = {\n",
    "        \"content\": enriched_text,\n",
    "        \"tfidf_outliers\": tfidf_outliers_list,\n",
    "        \"sentiment_polarity\": sentiment[\"polarity\"],\n",
    "        \"sentiment_subjectivity\": sentiment[\"subjectivity\"],\n",
    "        \"grammar_errors\": grammar[\"grammar_errors\"],\n",
    "        \"sentence_count\": grammar[\"sentence_count\"],\n",
    "        \"entity_count\": entity_density[\"entity_count\"],\n",
    "        \"text_length\": entity_density[\"text_length\"],\n",
    "    }\n",
    "\n",
    "    # ‚úÖ Print the first processed article for review (if in DEBUG mode)\n",
    "    if DEBUG_MODE:\n",
    "        print(\"\\nüîç **Test Entry Preview Before DB Commit** üîç\")\n",
    "        print(f\"üìå **Article ID:** {article_id}\")\n",
    "        print(f\"üìú **Content (Snippet):** {enriched_text[:500]}...\")  # Show first 500 chars\n",
    "        print(f\"üìä **Linguistic Analysis:**\")\n",
    "        print(f\"   - TF-IDF Outliers: {tfidf_outliers_list}\")\n",
    "        print(f\"   - Sentiment Polarity: {sentiment['polarity']}\")\n",
    "        print(f\"   - Sentiment Subjectivity: {sentiment['subjectivity']}\")\n",
    "        print(f\"   - Grammar Errors: {grammar['grammar_errors']}\")\n",
    "        print(f\"   - Sentence Count: {grammar['sentence_count']}\")\n",
    "        print(f\"   - Entity Count: {entity_density['entity_count']}\")\n",
    "        print(f\"   - Text Length: {entity_density['text_length']}\")\n",
    "        print(\"\\nüõ†Ô∏è **Confirm before committing to ChromaDB!**\")\n",
    "        break  # Only process and print 1 entry in DEBUG mode\n",
    "\n",
    "print(f\"‚úÖ Linguistic analysis completed for {len(final_articles)} articles!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Entries before putting them into DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Previewing 5 articles before committing to ChromaDB...\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ CONFIGURE SETTINGS\n",
    "NUM_SAMPLES = 5  # Change this to inspect X articles\n",
    "RANDOM_SAMPLES = True  # True = Random X articles, False = First X\n",
    "\n",
    "print(f\"üîç Previewing {NUM_SAMPLES} articles before committing to ChromaDB...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample & Display Enriched Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ **Sample 1/1 - Article ID:** https://newsone.com/5939034/presidents-are-judged-by-history-through-the-lens-of-morality/\n",
      "üìú **Enriched Content (Snippet):**\n",
      "A statue of Abraham Lincoln, the 16th president of the United States, sits in the Lincoln Memorial in Washington. Historians consistently have given Lincoln, the Great Emancipator, their highest rating because of his leadership during the Civil War. Jakub Porzycki/NurPhoto via Getty Images\n",
      "\n",
      "What will be former President Joe Biden‚Äôs legacy? How will Americans in the future consider his four years in office?\n",
      "\n",
      "Every American president lands in the history books. And historians‚Äô assessments of their performance have been generally consistent over time. But some presidents‚Äô rankings have changed as the nation ‚Äì and historians themselves ‚Äì reassessed the country‚Äôs values and priorities.\n",
      "\n",
      "Historians have been ranking presidents in surveys since Arthur Schlesinger Sr.‚Äôs first such study appeared in Life magazine in 1948. The results of that survey categorized Presidents Abraham Lincoln, George Washington, Franklin D. Roosevelt, Woodrow Wilson, Thomas Jefferson and Andrew Jackson as ‚Äúgreat.‚Äù\n",
      "\n",
      "A...\n",
      "====================================================================================================\n",
      "\n",
      "‚úÖ Displayed 1 enriched articles.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# ‚úÖ Check if `expanded_articles` contains data\n",
    "if not expanded_articles:\n",
    "    print(\"‚ö†Ô∏è No enriched articles found in memory. Ensure RAG processing has completed.\")\n",
    "else:\n",
    "    # ‚úÖ Select a subset of articles\n",
    "    article_keys = list(expanded_articles.keys())\n",
    "\n",
    "    if RANDOM_SAMPLES and len(article_keys) >= NUM_SAMPLES:\n",
    "        sample_ids = random.sample(article_keys, NUM_SAMPLES)\n",
    "    else:\n",
    "        sample_ids = article_keys[:NUM_SAMPLES]  # Get first X articles if not enough for random\n",
    "\n",
    "    # ‚úÖ Display selected enriched articles\n",
    "    for idx, article_id in enumerate(sample_ids, start=1):\n",
    "        enriched_text = expanded_articles.get(article_id, \"[No content found]\")  # Safe retrieval\n",
    "        print(f\"\\nüîπ **Sample {idx}/{len(sample_ids)} - Article ID:** {article_id}\")\n",
    "        print(f\"üìú **Enriched Content (Snippet):**\\n{enriched_text[:1000]}...\")  # First 1000 chars\n",
    "        print(\"=\" * 100)\n",
    "\n",
    "    print(f\"\\n‚úÖ Displayed {len(sample_ids)} enriched articles.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DF - Display whole entry for an article\n",
    "\n",
    "Create a Dataframe to see the article details in separate sections:\n",
    "- Fact-Checking & Wikipedia Summary\n",
    "- Linguistic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç **DEBUG MODE: FULLY ENRICHED ARTICLE READY FOR CHROMA** üîç\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>published_date</th>\n",
       "      <th>source</th>\n",
       "      <th>author</th>\n",
       "      <th>category</th>\n",
       "      <th>content</th>\n",
       "      <th>TF-IDF Outliers</th>\n",
       "      <th>Sentiment Polarity</th>\n",
       "      <th>Sentiment Subjectivity</th>\n",
       "      <th>Grammar Errors</th>\n",
       "      <th>Sentence Count</th>\n",
       "      <th>Entity Count</th>\n",
       "      <th>Text Length</th>\n",
       "      <th>fact_checking_summary</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://newsone.com/5939034/presidents-are-jud...</td>\n",
       "      <td>Presidents Are Often Judged By History Through...</td>\n",
       "      <td>https://newsone.com/5939034/presidents-are-jud...</td>\n",
       "      <td>2025-02-17T14:33:46+00:00</td>\n",
       "      <td>Unknown source</td>\n",
       "      <td>George R. Goethals, University of Richmond</td>\n",
       "      <td>general</td>\n",
       "      <td>A statue of Abraham Lincoln, the 16th presiden...</td>\n",
       "      <td>[2021, surveys, historians, president, preside...</td>\n",
       "      <td>0.113065</td>\n",
       "      <td>0.431745</td>\n",
       "      <td>128707</td>\n",
       "      <td>3856</td>\n",
       "      <td>12364</td>\n",
       "      <td>108308</td>\n",
       "      <td>Fact-Check: ['‚ö†Ô∏è Fact-check API error: 403 Cli...</td>\n",
       "      <td>ready</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          article_id  \\\n",
       "0  https://newsone.com/5939034/presidents-are-jud...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Presidents Are Often Judged By History Through...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://newsone.com/5939034/presidents-are-jud...   \n",
       "\n",
       "              published_date          source  \\\n",
       "0  2025-02-17T14:33:46+00:00  Unknown source   \n",
       "\n",
       "                                       author category  \\\n",
       "0  George R. Goethals, University of Richmond  general   \n",
       "\n",
       "                                             content  \\\n",
       "0  A statue of Abraham Lincoln, the 16th presiden...   \n",
       "\n",
       "                                     TF-IDF Outliers  Sentiment Polarity  \\\n",
       "0  [2021, surveys, historians, president, preside...            0.113065   \n",
       "\n",
       "   Sentiment Subjectivity  Grammar Errors  Sentence Count  Entity Count  \\\n",
       "0                0.431745          128707            3856         12364   \n",
       "\n",
       "   Text Length                              fact_checking_summary status  \n",
       "0       108308  Fact-Check: ['‚ö†Ô∏è Fact-check API error: 403 Cli...  ready  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ **Article is fully processed and marked as 'ready'!**\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# ‚úÖ Ensure there's an article to process\n",
    "if not final_articles:\n",
    "    print(\"‚ö†Ô∏è No processed articles found. Ensure the pipeline has run.\")\n",
    "else:\n",
    "    # ‚úÖ Get the single article (since DEBUG_MODE is True)\n",
    "    article_id, enriched_data = list(final_articles.items())[0]\n",
    "\n",
    "    # ‚úÖ Extract sections\n",
    "    fact_checking_section = enriched_data[\"content\"].split(\"\\n\\nFact-Checking Data:\\n\")[-1]\n",
    "\n",
    "    # ‚úÖ Fetch full article details from ChromaDB\n",
    "    article_data = collection.get([article_id])\n",
    "    \n",
    "    if not article_data[\"documents\"]:\n",
    "        print(f\"‚ö†Ô∏è Article ID {article_id} not found in ChromaDB!\")\n",
    "    else:\n",
    "        full_article = {\n",
    "            \"article_id\": article_id,\n",
    "            \"title\": article_data[\"metadatas\"][0].get(\"title\", \"Unknown Title\"),\n",
    "            \"url\": article_data[\"metadatas\"][0].get(\"url\", \"Unknown URL\"),\n",
    "            \"published_date\": article_data[\"metadatas\"][0].get(\"published_date\", \"Unknown Date\"),\n",
    "            \"source\": article_data[\"metadatas\"][0].get(\"source\", \"Unknown Source\"),\n",
    "            \"author\": article_data[\"metadatas\"][0].get(\"author\", \"Unknown Author\"),\n",
    "            \"category\": article_data[\"metadatas\"][0].get(\"category\", \"Unknown Category\"),\n",
    "            \"content\": article_data[\"documents\"][0],  # Full article text\n",
    "        }\n",
    "\n",
    "        # ‚úÖ Append linguistic analysis\n",
    "        linguistic_analysis = {\n",
    "            \"TF-IDF Outliers\": enriched_data[\"tfidf_outliers\"],\n",
    "            \"Sentiment Polarity\": enriched_data[\"sentiment_polarity\"],\n",
    "            \"Sentiment Subjectivity\": enriched_data[\"sentiment_subjectivity\"],\n",
    "            \"Grammar Errors\": enriched_data[\"grammar_errors\"],\n",
    "            \"Sentence Count\": enriched_data[\"sentence_count\"],\n",
    "            \"Entity Count\": enriched_data[\"entity_count\"],\n",
    "            \"Text Length\": enriched_data[\"text_length\"],\n",
    "        }\n",
    "\n",
    "        # ‚úÖ Combine all data into one DataFrame\n",
    "        full_data = {**full_article, **linguistic_analysis, \"fact_checking_summary\": fact_checking_section, \"status\": \"ready\"}\n",
    "\n",
    "        # ‚úÖ Convert to DataFrame\n",
    "        df = pd.DataFrame([full_data])\n",
    "\n",
    "        # ‚úÖ Display the full enriched article\n",
    "        print(\"\\nüîç **DEBUG MODE: FULLY ENRICHED ARTICLE READY FOR CHROMA** üîç\")\n",
    "        display(df)\n",
    "\n",
    "        print(\"\\n‚úÖ **Article is fully processed and marked as 'ready'!**\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Enriched Articles Back to ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully stored 1 enriched articles in ChromaDB!\n"
     ]
    }
   ],
   "source": [
    "import json  # ‚úÖ Import JSON to convert lists\n",
    "\n",
    "# ‚úÖ Store enriched articles after RAG in ChromaDB as a new indexed entry\n",
    "new_entries = []\n",
    "for index, (article_id, enriched_data) in enumerate(final_articles.items(), start=1):\n",
    "    # ‚úÖ Create a unique new ID for the enriched version\n",
    "    new_entry_id = f\"rag_{index}\"  # Example: rag_1, rag_2, rag_3...\n",
    "\n",
    "    # ‚úÖ Fetch full article details from ChromaDB\n",
    "    article_data = collection.get([article_id])\n",
    "    \n",
    "    if not article_data[\"documents\"]:\n",
    "        print(f\"‚ö†Ô∏è Article ID {article_id} not found in ChromaDB. Skipping...\")\n",
    "        continue\n",
    "    \n",
    "    full_article = {\n",
    "        \"original_article_id\": article_id,  # ‚úÖ Keeps reference to original entry\n",
    "        \"title\": article_data[\"metadatas\"][0].get(\"title\", \"Unknown Title\"),\n",
    "        \"url\": article_data[\"metadatas\"][0].get(\"url\", \"Unknown URL\"),\n",
    "        \"published_date\": article_data[\"metadatas\"][0].get(\"published_date\", \"Unknown Date\"),\n",
    "        \"source\": article_data[\"metadatas\"][0].get(\"source\", \"Unknown Source\"),\n",
    "        \"author\": article_data[\"metadatas\"][0].get(\"author\", \"Unknown Author\"),\n",
    "        \"category\": article_data[\"metadatas\"][0].get(\"category\", \"Unknown Category\"),\n",
    "    }\n",
    "\n",
    "    # ‚úÖ Convert TF-IDF Outliers list to a JSON string\n",
    "    tfidf_outliers_str = json.dumps(enriched_data[\"tfidf_outliers\"])  # ‚úÖ Converts list to a string\n",
    "\n",
    "    # ‚úÖ Merge with linguistic analysis + status = \"ready\"\n",
    "    enriched_entry = {\n",
    "        **full_article,  \n",
    "        \"enriched_content\": enriched_data[\"content\"],  # Full RAG-enriched text\n",
    "        \"TF-IDF Outliers\": tfidf_outliers_str,  # ‚úÖ Now stored as a JSON string\n",
    "        \"Sentiment Polarity\": enriched_data[\"sentiment_polarity\"],\n",
    "        \"Sentiment Subjectivity\": enriched_data[\"sentiment_subjectivity\"],\n",
    "        \"Grammar Errors\": enriched_data[\"grammar_errors\"],\n",
    "        \"Sentence Count\": enriched_data[\"sentence_count\"],\n",
    "        \"Entity Count\": enriched_data[\"entity_count\"],\n",
    "        \"Text Length\": enriched_data[\"text_length\"],\n",
    "        \"fact_checking_summary\": enriched_data[\"content\"].split(\"\\n\\nFact-Checking Data:\\n\")[-1],\n",
    "        \"status\": \"ready\",  # ‚úÖ Marks the enriched article as complete\n",
    "    }\n",
    "\n",
    "    # ‚úÖ Store in ChromaDB as a new indexed entry\n",
    "    collection.add(\n",
    "        ids=[new_entry_id],  # Unique indexed ID (rag_1, rag_2, etc.)\n",
    "        documents=[enriched_data[\"content\"]],\n",
    "        metadatas=[enriched_entry]\n",
    "    )\n",
    "\n",
    "    new_entries.append(new_entry_id)\n",
    "\n",
    "print(f\"‚úÖ Successfully stored {len(new_entries)} enriched articles in ChromaDB!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a PD Dataframe from RAG entries in ChromaDB\n",
    "An entry gets \"status = ready\" once it goes through RAG.\n",
    "* Retrieves all entries from ChromaDB where status = \"ready\".\n",
    "* Allows toggling between fetching all available entries or a limited number.\n",
    "* Stores the results in a pandas.DataFrame for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>published_date</th>\n",
       "      <th>source</th>\n",
       "      <th>author</th>\n",
       "      <th>category</th>\n",
       "      <th>enriched_content</th>\n",
       "      <th>TF-IDF Outliers</th>\n",
       "      <th>Sentiment Polarity</th>\n",
       "      <th>Sentiment Subjectivity</th>\n",
       "      <th>Grammar Errors</th>\n",
       "      <th>Sentence Count</th>\n",
       "      <th>Entity Count</th>\n",
       "      <th>Text Length</th>\n",
       "      <th>fact_checking_summary</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://newsone.com/5939034/presidents-are-jud...</td>\n",
       "      <td>Presidents Are Often Judged By History Through...</td>\n",
       "      <td>https://newsone.com/5939034/presidents-are-jud...</td>\n",
       "      <td>2025-02-17T14:33:46+00:00</td>\n",
       "      <td>Unknown source</td>\n",
       "      <td>George R. Goethals, University of Richmond</td>\n",
       "      <td>general</td>\n",
       "      <td>A statue of Abraham Lincoln, the 16th presiden...</td>\n",
       "      <td>[2021, surveys, historians, president, preside...</td>\n",
       "      <td>0.113065</td>\n",
       "      <td>0.431745</td>\n",
       "      <td>128707</td>\n",
       "      <td>3856</td>\n",
       "      <td>12364</td>\n",
       "      <td>108308</td>\n",
       "      <td>Fact-Check: ['‚ö†Ô∏è Fact-check API error: 403 Cli...</td>\n",
       "      <td>ready</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          article_id  \\\n",
       "0  https://newsone.com/5939034/presidents-are-jud...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Presidents Are Often Judged By History Through...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://newsone.com/5939034/presidents-are-jud...   \n",
       "\n",
       "              published_date          source  \\\n",
       "0  2025-02-17T14:33:46+00:00  Unknown source   \n",
       "\n",
       "                                       author category  \\\n",
       "0  George R. Goethals, University of Richmond  general   \n",
       "\n",
       "                                    enriched_content  \\\n",
       "0  A statue of Abraham Lincoln, the 16th presiden...   \n",
       "\n",
       "                                     TF-IDF Outliers  Sentiment Polarity  \\\n",
       "0  [2021, surveys, historians, president, preside...            0.113065   \n",
       "\n",
       "   Sentiment Subjectivity  Grammar Errors  Sentence Count  Entity Count  \\\n",
       "0                0.431745          128707            3856         12364   \n",
       "\n",
       "   Text Length                              fact_checking_summary status  \n",
       "0       108308  Fact-Check: ['‚ö†Ô∏è Fact-check API error: 403 Cli...  ready  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Retrieved 1 articles with status = 'ready' from ChromaDB.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# ‚úÖ Toggle: Fetch all or limit the number of entries\n",
    "FETCH_ALL_READY = True  # Set to False to limit the number of entries\n",
    "LIMIT_ENTRIES = 10  # Only used if FETCH_ALL_READY = False\n",
    "\n",
    "# ‚úÖ Fetch all entries from ChromaDB\n",
    "all_entries = collection.get()\n",
    "\n",
    "# ‚úÖ Extract metadata and documents for only \"ready\" entries\n",
    "filtered_entries = []\n",
    "for i, metadata in enumerate(all_entries[\"metadatas\"]):\n",
    "    if metadata.get(\"status\") == \"ready\":\n",
    "        entry = {\n",
    "            \"article_id\": metadata.get(\"original_article_id\", \"Unknown\"),\n",
    "            \"title\": metadata.get(\"title\", \"Unknown Title\"),\n",
    "            \"url\": metadata.get(\"url\", \"Unknown URL\"),\n",
    "            \"published_date\": metadata.get(\"published_date\", \"Unknown Date\"),\n",
    "            \"source\": metadata.get(\"source\", \"Unknown Source\"),\n",
    "            \"author\": metadata.get(\"author\", \"Unknown Author\"),\n",
    "            \"category\": metadata.get(\"category\", \"Unknown Category\"),\n",
    "            \"enriched_content\": all_entries[\"documents\"][i],  # Full enriched text\n",
    "            \"TF-IDF Outliers\": json.loads(metadata.get(\"TF-IDF Outliers\", \"[]\")),  # Convert JSON string back to list\n",
    "            \"Sentiment Polarity\": metadata.get(\"Sentiment Polarity\"),\n",
    "            \"Sentiment Subjectivity\": metadata.get(\"Sentiment Subjectivity\"),\n",
    "            \"Grammar Errors\": metadata.get(\"Grammar Errors\"),\n",
    "            \"Sentence Count\": metadata.get(\"Sentence Count\"),\n",
    "            \"Entity Count\": metadata.get(\"Entity Count\"),\n",
    "            \"Text Length\": metadata.get(\"Text Length\"),\n",
    "            \"fact_checking_summary\": metadata.get(\"fact_checking_summary\", \"\"),\n",
    "            \"status\": metadata.get(\"status\"),\n",
    "        }\n",
    "        filtered_entries.append(entry)\n",
    "\n",
    "# ‚úÖ Apply limit if not fetching all entries\n",
    "if not FETCH_ALL_READY:\n",
    "    filtered_entries = filtered_entries[:LIMIT_ENTRIES]\n",
    "\n",
    "# ‚úÖ Convert to Pandas DataFrame\n",
    "df_ready = pd.DataFrame(filtered_entries)\n",
    "\n",
    "# ‚úÖ Display DataFrame in Jupyter Notebook\n",
    "display(df_ready)\n",
    "\n",
    "print(f\"\\n‚úÖ Retrieved {len(df_ready)} articles with status = 'ready' from ChromaDB.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
