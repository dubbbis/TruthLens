{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of the Code\n",
    "\n",
    "1Ô∏è‚É£ **Fetch news from Mediastack**  \n",
    "   - Fetches articles based on your API key and fetch limit (e.g., 10 articles).\n",
    "\n",
    "2Ô∏è‚É£ **Check for paywalled articles**  \n",
    "   - Skips articles from known paywalled domains (e.g., New York Times).\n",
    "\n",
    "3Ô∏è‚É£ **Extract full article text**  \n",
    "   - Attempts to extract text using `newspaper3k`, `Unstructured`, and `BeautifulSoup`.\n",
    "\n",
    "4Ô∏è‚É£ **Store articles in JSON**  \n",
    "   - Saves the articles in a JSON file (`news.json`).\n",
    "\n",
    "5Ô∏è‚É£ **Convert text to embeddings**  \n",
    "   - Uses the `SentenceTransformer` to generate embeddings for each article's text.\n",
    "\n",
    "6Ô∏è‚É£ **Store embeddings in ChromaDB**  \n",
    "   - Adds the generated embeddings into ChromaDB for semantic search.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- ## NOTE: the current chroma_db directory is one up, if this structure changes, it needs to change too. \\\n",
    "find it below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to install\n",
    "\n",
    "pip install fake-useragent && pip install newspaper3k && pip install lxml_html_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç [1/50] Processing: https://www.marketbeat.com/instant-alerts/blue-zone-wealth-advisors-llc-acquires-6038-shares-of-linde-plc-nasdaqlin-2025-02-16/\n",
      "üîç [2/50] Processing: https://www.marketbeat.com/instant-alerts/blue-zone-wealth-advisors-llc-acquires-4369-shares-of-costar-group-inc-nasdaqcsgp-2025-02-16/\n",
      "üîç [3/50] Processing: https://www.dailymail.co.uk/news/article-14405407/Dubai-Brits-regret-new-lives-desperate-come-back.html?ns_mchannel=rss&ito=1490&ns_campaign=1490\n",
      "üîç [4/50] Processing: https://www.dailymail.co.uk/news/article-14405039/Ruth-Ellis-grandson-hanged-Britain-ITV-drama.html?ns_mchannel=rss&ito=1490&ns_campaign=1490\n",
      "üîç [5/50] Processing: https://www.essentiallysports.com/nascar-news-denny-hamlin-ready-to-betray-jgr-teammate-as-he-reveals-shocking-heel-turn-in-cole-custer-callout/\n",
      "üîç [6/50] Processing: https://www.nme.com/news/gaming-news/elden-ring-nightreign-preview-newtork-test-positive-review-3838620?utm_source=rss&utm_medium=rss&utm_campaign=elden-ring-nightreign-preview-newtork-test-positive-review\n",
      "üîç [7/50] Processing: https://www.marketbeat.com/instant-alerts/klabin-sa-otcmktsklbay-short-interest-update-2025-02-17/\n",
      "üîç [8/50] Processing: https://www.marketbeat.com/instant-alerts/keppel-ltd-otcmktskpely-short-interest-down-83-in-january-2025-02-17/\n",
      "üîç [9/50] Processing: https://www.marketbeat.com/instant-alerts/keppel-reit-otcmktskrevf-sees-significant-decline-in-short-interest-2025-02-17/\n",
      "üîç [10/50] Processing: https://www.dailymail.co.uk/health/article-14403553/ebola-virus-nyc-patients-hospital-cases.html?ns_mchannel=rss&ito=1490&ns_campaign=1490\n",
      "üîç [11/50] Processing: https://www.hellomagazine.com/film/814659/itv-thriller-protection-with-happy-valley-grantchester-stars-trailer/\n",
      "üîç [12/50] Processing: https://www.essentiallysports.com/nfl-active-news-ronika-stone-swoons-over-jordan-love-in-a-throwback-picture-as-packers-qb-mulls-over-ups-and-downs-of-last-season/\n",
      "üîç [13/50] Processing: https://www.wigantoday.net/business/consumer/maternity-leave-uk-statutory-allowance-paternity-pay-rise-april-4994495\n",
      "üîç [14/50] Processing: https://seekingalpha.com/article/4758964-sp500-spx-prepping-for-the-breakout-technical-analysis?source=feed_all_articles\n",
      "üîç [15/50] Processing: https://insightssuccess.com/cold-water-therapy-and-the-nervous-system-an-overview/\n",
      "üîç [16/50] Processing: https://www.mymotherlode.com/news/world/3534024/here-are-some-takeaways-from-the-first-month-of-trumps-mideast-diplomacy.html\n",
      "üîç [17/50] Processing: https://vtdigger.org/2025/02/17/rep-edye-graning-laying-the-groundwork-for-a-stronger-vermont-workforce/\n",
      "üîç [18/50] Processing: https://www.essentiallysports.com/us-sports-news-nhl-news-what-is-brad-marchands-twenty-twenty-five-net-worth-know-boston-bruins-stars-nhl-contract-salary-cap-and-business-details/\n",
      "üîç [19/50] Processing: https://businessday.ng/news/article/oyetola-denies-allegation-of-destabilization-plot/\n",
      "üîç [20/50] Processing: https://www.deccanchronicle.com/nation/from-snakes-crocodiles-to-trimming-beard-us-deportees-from-punjab-recall-perilous-donkey-route-1861750\n",
      "üîç [21/50] Processing: https://bernews.com/2025/02/feb17weekend-reports-photos-videos-links-more/\n",
      "üîç [22/50] Processing: https://www.marketbeat.com/instant-alerts/evergreen-wealth-management-llc-has-359-million-stock-holdings-in-elevance-health-inc-nyseelv-2025-02-17/\n",
      "üîç [23/50] Processing: https://www.marketbeat.com/instant-alerts/cutler-investment-counsel-llc-takes-position-in-netflix-inc-nasdaqnflx-2025-02-17/\n",
      "üîç [24/50] Processing: https://www.alternet.org/trump-executive-power/\n",
      "üîç [25/50] Processing: https://www.marketbeat.com/instant-alerts/cutler-investment-counsel-llc-purchases-new-position-in-the-southern-company-nyseso-2025-02-17/\n",
      "üîç [26/50] Processing: https://www.etfdailynews.com/2025/02/17/life-planning-partners-inc-purchases-new-stake-in-exxon-mobil-co-nysexom/\n",
      "üîç [27/50] Processing: https://www.mymotherlode.com/news/europe/3533996/popes-planned-commitments-in-doubt-as-hospital-treatment-for-respiratory-infection-continues.html\n",
      "üîç [28/50] Processing: https://www.marketbeat.com/instant-alerts/cvs-health-co-nysecvs-shares-sold-by-cutler-investment-counsel-llc-2025-02-17/\n",
      "üîç [29/50] Processing: https://www.marketbeat.com/instant-alerts/cutler-investment-counsel-llc-takes-469-million-position-in-pfizer-inc-nysepfe-2025-02-17/\n",
      "üîç [30/50] Processing: https://www.marketbeat.com/instant-alerts/cutler-investment-counsel-llc-sells-7200-shares-of-nike-inc-nysenke-2025-02-17/\n",
      "üîç [31/50] Processing: https://www.marketbeat.com/instant-alerts/cutler-investment-counsel-llc-has-8-million-stock-position-in-dupont-de-nemours-inc-nysedd-2025-02-17/\n",
      "üîç [32/50] Processing: https://www.marketbeat.com/instant-alerts/cutler-investment-counsel-llc-has-934-million-holdings-in-the-pnc-financial-services-group-inc-nysepnc-2025-02-17/\n",
      "üîç [33/50] Processing: https://www.marketbeat.com/instant-alerts/medtronic-plc-nysemdt-shares-sold-by-cutler-investment-counsel-llc-2025-02-17/\n",
      "üîç [34/50] Processing: https://www.marketbeat.com/instant-alerts/cutler-investment-counsel-llc-sells-1025-shares-of-international-business-machines-co-nyseibm-2025-02-17/\n",
      "üîç [35/50] Processing: https://www.marketbeat.com/instant-alerts/cutler-investment-counsel-llc-reduces-holdings-in-verizon-communications-inc-nysevz-2025-02-17/\n",
      "üîç [36/50] Processing: https://www.marketbeat.com/instant-alerts/cutler-investment-counsel-llc-sells-1859-shares-of-texas-instruments-incorporated-nasdaqtxn-2025-02-17/\n",
      "üîç [37/50] Processing: https://financialpost.com/globe-newswire/now-book-it-expands-global-reach-to-power-bookings-for-restaurants-in-canada\n",
      "üîç [38/50] Processing: https://www.marketbeat.com/instant-alerts/deere-company-nysede-stock-holdings-cut-by-cutler-investment-counsel-llc-2025-02-17/\n",
      "üîç [39/50] Processing: https://www.marketbeat.com/instant-alerts/cutler-investment-counsel-llc-lowers-stake-in-the-charles-schwab-co-nyseschw-2025-02-17/\n",
      "üîç [40/50] Processing: https://www.marketbeat.com/instant-alerts/mcdonalds-co-nysemcd-stock-holdings-reduced-by-cutler-investment-counsel-llc-2025-02-17/\n",
      "üîç [41/50] Processing: https://www.marketbeat.com/instant-alerts/cutler-investment-counsel-llc-sells-1548-shares-of-republic-services-inc-nysersg-2025-02-17/\n",
      "üîç [42/50] Processing: https://www.marketbeat.com/instant-alerts/cutler-investment-counsel-llc-invests-1950-million-in-blackrock-inc-nyseblk-2025-02-17/\n",
      "üîç [43/50] Processing: https://www.marketbeat.com/instant-alerts/cutler-investment-counsel-llc-sells-1127-shares-of-caterpillar-inc-nysecat-2025-02-17/\n",
      "üîç [44/50] Processing: https://www.marketbeat.com/instant-alerts/highview-capital-management-llc-de-buys-shares-of-6500-bank-of-america-co-nysebac-2025-02-17/\n",
      "üîç [45/50] Processing: https://www.marketbeat.com/instant-alerts/highview-capital-management-llc-de-makes-new-287000-investment-in-the-cigna-group-nyseci-2025-02-17/\n",
      "üîç [46/50] Processing: https://www.marketbeat.com/instant-alerts/highview-capital-management-llc-de-buys-new-shares-in-purecycle-technologies-inc-nasdaqpct-2025-02-17/\n",
      "üîç [47/50] Processing: https://www.marketbeat.com/instant-alerts/highview-capital-management-llc-de-makes-new-investment-in-air-products-and-chemicals-inc-nyseapd-2025-02-17/\n",
      "üîç [48/50] Processing: https://www.marketbeat.com/instant-alerts/autozone-inc-nyseazo-shares-sold-by-highview-capital-management-llc-de-2025-02-17/\n",
      "üîç [49/50] Processing: https://www.marketbeat.com/instant-alerts/highview-capital-management-llc-de-takes-775000-position-in-emerson-electric-co-nyseemr-2025-02-17/\n",
      "üîç [50/50] Processing: https://www.marketbeat.com/instant-alerts/highview-capital-management-llc-de-acquires-shares-of-3898-vulcan-materials-nysevmc-2025-02-17/\n",
      "‚úÖ 50 articles saved in 'news.json'.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "from unstructured.partition.html import partition_html\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "from newspaper import Article\n",
    "\n",
    "# üîπ CONFIGURATION: Define the Mediastack API and the number of articles to fetch\n",
    "API_KEY = \"356bb7cd80f02083d604ba6ba1dfadd8\"\n",
    "MAX_ARTICLES = 50  # Change this to limit results\n",
    "\n",
    "# Mediastack Base URL\n",
    "BASE_URL = f\"http://api.mediastack.com/v1/news?access_key={API_KEY}&countries=us&limit={MAX_ARTICLES}\"\n",
    "\n",
    "# List of known paywalled domains\n",
    "paywalled_domains = [\"nytimes.com\", \"washingtonpost.com\", \"theatlantic.com\", \"bloomberg.com\"]\n",
    "\n",
    "# User-Agent Rotator\n",
    "ua = UserAgent()\n",
    "\n",
    "def is_paywalled(url):\n",
    "    \"\"\"Check if the article is from a paywalled domain.\"\"\"\n",
    "    return any(domain in url for domain in paywalled_domains)\n",
    "\n",
    "def extract_full_text(url):\n",
    "    \"\"\"Extract full article text using newspaper3k, Unstructured, and BeautifulSoup.\"\"\"\n",
    "    try:\n",
    "        headers = {'User-Agent': ua.random}\n",
    "        page = requests.get(url, headers=headers, timeout=10)\n",
    "\n",
    "        if page.status_code != 200:\n",
    "            return f\"Error: Page returned status code {page.status_code}\"\n",
    "\n",
    "        # Attempt 1: newspaper3k (best for full-text extraction)\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        if len(article.text) > 500:\n",
    "            return article.text\n",
    "\n",
    "        # Attempt 2: Unstructured (fallback)\n",
    "        elements = partition_html(text=page.text)\n",
    "        extracted_text = \"\\n\".join([el.text for el in elements if el.text.strip()])\n",
    "        if len(extracted_text) > 500:\n",
    "            return extracted_text\n",
    "\n",
    "        # Attempt 3: BeautifulSoup (last resort)\n",
    "        soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "        paragraphs = soup.find_all(\"p\")\n",
    "        extracted_text = \"\\n\".join([p.get_text() for p in paragraphs])\n",
    "        return extracted_text if len(extracted_text) > 500 else \"Content could not be extracted.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error extracting content: {str(e)}\"\n",
    "\n",
    "# üîπ Fetch news from Mediastack\n",
    "response = requests.get(BASE_URL)\n",
    "news_data = response.json().get(\"data\", [])[:MAX_ARTICLES]  # Limit articles\n",
    "\n",
    "articles_list = []\n",
    "\n",
    "# üîπ Process each article\n",
    "for i, article in enumerate(news_data):\n",
    "    url = article.get(\"url\", \"\")\n",
    "\n",
    "    if not url or is_paywalled(url):\n",
    "        print(f\"üö´ Skipping paywalled article: {url}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"üîç [{i+1}/{MAX_ARTICLES}] Processing: {url}\")\n",
    "    full_text = extract_full_text(url)\n",
    "\n",
    "    # ‚úÖ Apply Fix: Ensure correct data types for each field\n",
    "    articles_list.append({\n",
    "        \"title\": article.get(\"title\", \"Unknown title\"),\n",
    "        \"url\": url,\n",
    "        \"published_date\": article.get(\"published_at\", \"Unknown date\"),\n",
    "        \"source_name\": article[\"source\"][\"name\"] if isinstance(article.get(\"source\"), dict) else \"Unknown source\",\n",
    "        \"author\": article[\"author\"] if isinstance(article.get(\"author\"), str) else \"Unknown author\",\n",
    "        \"category\": article[\"category\"] if isinstance(article.get(\"category\"), str) else \"Unknown category\",\n",
    "        \"content\": full_text\n",
    "    })\n",
    "\n",
    "    time.sleep(2)  # Avoid being blocked by rate limits\n",
    "\n",
    "# üîπ Save articles in JSON format\n",
    "with open(\"news.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(articles_list, f, indent=4)\n",
    "\n",
    "print(f\"‚úÖ {len(articles_list)} articles saved in 'news.json'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ChromaDB instance found. Using existing database.\n",
      "‚úÖ Collection 'news_articles' exists.\n",
      "‚úÖ ChromaDB is ready to use.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import chromadb\n",
    "\n",
    "# ‚úÖ Define ChromaDB path (stored one directory above)\n",
    "CHROMA_DB_PATH = \"../chroma_db\"\n",
    "\n",
    "# üîç Check if the ChromaDB folder exists\n",
    "if not os.path.exists(CHROMA_DB_PATH):\n",
    "    print(\"‚ö†Ô∏è ChromaDB instance not found. Creating a new one...\")\n",
    "    os.makedirs(CHROMA_DB_PATH)  # Create the folder if missing\n",
    "else:\n",
    "    print(\"‚úÖ ChromaDB instance found. Using existing database.\")\n",
    "\n",
    "# ‚úÖ Initialize ChromaDB\n",
    "client = chromadb.PersistentClient(path=CHROMA_DB_PATH)\n",
    "\n",
    "# ‚úÖ Get or Create Collection\n",
    "collection_name = \"news_articles\"\n",
    "\n",
    "try:\n",
    "    collection = client.get_collection(collection_name)\n",
    "    print(f\"‚úÖ Collection '{collection_name}' exists.\")\n",
    "except Exception:\n",
    "    print(f\"‚ö†Ô∏è Collection '{collection_name}' not found. Creating a new one...\")\n",
    "    collection = client.create_collection(collection_name)\n",
    "\n",
    "print(f\"‚úÖ ChromaDB is ready to use.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Converting articles to embeddings and storing them in ChromaDB...\n",
      "‚úÖ Articles converted to embeddings and stored in ChromaDB.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ‚úÖ Load articles from news.json\n",
    "with open(\"news.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    articles_list = json.load(f)\n",
    "\n",
    "# üîÑ Convert articles to embeddings and store in ChromaDB\n",
    "print(\"üîÑ Converting articles to embeddings and storing them in ChromaDB...\")\n",
    "\n",
    "# ‚úÖ Load embedding model\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# ‚úÖ Check existing document IDs in ChromaDB to prevent duplicates\n",
    "existing_ids = set(collection.get()[\"ids\"])\n",
    "\n",
    "new_entries = []\n",
    "for article in articles_list:\n",
    "    article_id = article[\"url\"]\n",
    "    if article_id not in existing_ids:  # Avoid duplicates\n",
    "        text = f\"{article['title']} {article['content']}\"\n",
    "        embedding = embedding_model.encode(text).tolist()\n",
    "\n",
    "        new_entries.append({\n",
    "            \"document\": text,\n",
    "            \"metadata\": {\n",
    "                \"title\": article[\"title\"],\n",
    "                \"url\": article[\"url\"],\n",
    "                \"published_date\": article[\"published_date\"],\n",
    "                \"source_name\": article[\"source_name\"],\n",
    "                \"author\": article[\"author\"],\n",
    "                \"category\": article[\"category\"]\n",
    "            },\n",
    "            \"id\": article_id,\n",
    "            \"embedding\": embedding\n",
    "        })\n",
    "\n",
    "# ‚úÖ Add new articles to ChromaDB\n",
    "if new_entries:\n",
    "    collection.add(\n",
    "        documents=[entry[\"document\"] for entry in new_entries],\n",
    "        metadatas=[entry[\"metadata\"] for entry in new_entries],\n",
    "        ids=[entry[\"id\"] for entry in new_entries],\n",
    "        embeddings=[entry[\"embedding\"] for entry in new_entries]\n",
    "    )\n",
    "    print(f\"‚úÖ {len(new_entries)} new articles added to ChromaDB.\")\n",
    "else:\n",
    "    print(\"üîπ No new articles added. Database is up to date.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîπ CONFIG: Set `purge_db = True` to DELETE & RESET the database\n",
    "purge_db = True  # Set to True to delete existing DB and start fresh\n",
    "\n",
    "# ‚úÖ Define ChromaDB path\n",
    "CHROMA_DB_PATH = \"./chroma_db\"\n",
    "COLLECTION_NAME = \"news_articles\"\n",
    "\n",
    "# üîç Check if ChromaDB exists\n",
    "if not os.path.exists(CHROMA_DB_PATH):\n",
    "    print(\"‚ö†Ô∏è ChromaDB instance not found. Creating a new one...\")\n",
    "    os.makedirs(CHROMA_DB_PATH)\n",
    "else:\n",
    "    print(\"‚úÖ ChromaDB instance found. Using existing database.\")\n",
    "\n",
    "# üî• Purge Database If `purge_db` is Enabled\n",
    "if purge_db:\n",
    "    print(\"‚ö†Ô∏è Purging existing ChromaDB...\")\n",
    "    shutil.rmtree(CHROMA_DB_PATH, ignore_errors=True)  # ‚úÖ Remove the directory properly\n",
    "    os.makedirs(CHROMA_DB_PATH, exist_ok=True)  # ‚úÖ Recreate empty directory\n",
    "    print(\"‚úÖ ChromaDB successfully reset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nimport shutil\\n\\n# üîπ CONFIG: Set `purge_db = True` to DELETE & RESET the database\\npurge_db = True  # Set to True to delete existing DB and start fresh\\n\\n# ‚úÖ Define ChromaDB path\\nCHROMA_DB_PATH = \"./chroma_db\"\\nCOLLECTION_NAME = \"news_articles\"\\n\\n# üîç Check if ChromaDB exists\\nif not os.path.exists(CHROMA_DB_PATH):\\n    print(\"‚ö†Ô∏è ChromaDB instance not found. Creating a new one...\")\\n    os.makedirs(CHROMA_DB_PATH)\\nelse:\\n    print(\"‚úÖ ChromaDB instance found. Using existing database.\")\\n\\n# üî• Purge Database If `purge_db` is Enabled\\nif purge_db:\\n    print(\"‚ö†Ô∏è Purging existing ChromaDB...\")\\n    shutil.rmtree(CHROMA_DB_PATH, ignore_errors=True)  # ‚úÖ Remove the directory properly\\n    os.makedirs(CHROMA_DB_PATH, exist_ok=True)  # ‚úÖ Recreate empty directory\\n    print(\"‚úÖ ChromaDB successfully reset.\")\\n    \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "import shutil\n",
    "\n",
    "# üîπ CONFIG: Set `purge_db = True` to DELETE & RESET the database\n",
    "purge_db = True  # Set to True to delete existing DB and start fresh\n",
    "\n",
    "# ‚úÖ Define ChromaDB path\n",
    "CHROMA_DB_PATH = \"./chroma_db\"\n",
    "COLLECTION_NAME = \"news_articles\"\n",
    "\n",
    "# üîç Check if ChromaDB exists\n",
    "if not os.path.exists(CHROMA_DB_PATH):\n",
    "    print(\"‚ö†Ô∏è ChromaDB instance not found. Creating a new one...\")\n",
    "    os.makedirs(CHROMA_DB_PATH)\n",
    "else:\n",
    "    print(\"‚úÖ ChromaDB instance found. Using existing database.\")\n",
    "\n",
    "# üî• Purge Database If `purge_db` is Enabled\n",
    "if purge_db:\n",
    "    print(\"‚ö†Ô∏è Purging existing ChromaDB...\")\n",
    "    shutil.rmtree(CHROMA_DB_PATH, ignore_errors=True)  # ‚úÖ Remove the directory properly\n",
    "    os.makedirs(CHROMA_DB_PATH, exist_ok=True)  # ‚úÖ Recreate empty directory\n",
    "    print(\"‚úÖ ChromaDB successfully reset.\")\n",
    "    \n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
