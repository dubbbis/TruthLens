{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of the Code\n",
    "\n",
    "1Ô∏è‚É£ **Fetch news from Mediastack**  \n",
    "   - Fetches articles based on your API key and fetch limit (e.g., 10 articles).\n",
    "\n",
    "2Ô∏è‚É£ **Check for paywalled articles**  \n",
    "   - Skips articles from known paywalled domains (e.g., New York Times).\n",
    "\n",
    "3Ô∏è‚É£ **Extract full article text**  \n",
    "   - Attempts to extract text using `newspaper3k`, `Unstructured`, and `BeautifulSoup`.\n",
    "\n",
    "4Ô∏è‚É£ **Store articles in JSON**  \n",
    "   - Saves the articles in a JSON file (`news.json`).\n",
    "\n",
    "5Ô∏è‚É£ **Convert text to embeddings**  \n",
    "   - Uses the `SentenceTransformer` to generate embeddings for each article's text.\n",
    "\n",
    "6Ô∏è‚É£ **Store embeddings in ChromaDB**  \n",
    "   - Adds the generated embeddings into ChromaDB for semantic search.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- ## NOTE: the current chroma_db directory is one up, if this structure changes, it needs to change too. \\\n",
    "find it below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to install\n",
    "\n",
    "pip install fake-useragent && pip install newspaper3k && pip install lxml_html_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from unstructured.partition.html import partition_html\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "from newspaper import Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"356bb7cd80f02083d604ba6ba1dfadd8\"\n",
    "BASE_URL = f\"http://api.mediastack.com/v1/news?access_key={API_KEY}&countries=us&limit={MAX_ARTICLES}\"\n",
    "\n",
    "\n",
    "## Run this if you want to check that the API key works\n",
    "\n",
    "#print(\"üîç Checking API Response:\")\n",
    "#print(json.dumps(response.json(), indent=4))  # Pretty-print the JSON response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION\n",
    "MAX_ARTICLES = 10  # Change this to limit results\n",
    "\n",
    "\n",
    "NEWS_DIR = \"NEWS_FILES\"\n",
    "os.makedirs(NEWS_DIR, exist_ok=True)  # Ensure archive directory exists\n",
    "\n",
    "# ‚úÖ User-Agent Rotator & Paywall Handling\n",
    "ua = UserAgent()\n",
    "paywalled_domains = {\"nytimes.com\", \"washingtonpost.com\", \"theatlantic.com\", \"bloomberg.com\"}\n",
    "\n",
    "def is_paywalled(url):\n",
    "    return any(domain in url for domain in paywalled_domains)\n",
    "\n",
    "def extract_full_text(url):\n",
    "    \"\"\"Extracts article content using newspaper3k, Unstructured, and BeautifulSoup.\"\"\"\n",
    "    try:\n",
    "        headers = {'User-Agent': ua.random}\n",
    "        page = requests.get(url, headers=headers, timeout=10)\n",
    "\n",
    "        if page.status_code != 200:\n",
    "            return f\"Error: Page returned status code {page.status_code}\"\n",
    "\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        if len(article.text) > 500:\n",
    "            return article.text\n",
    "\n",
    "        elements = partition_html(text=page.text)\n",
    "        extracted_text = \"\\n\".join([el.text for el in elements if el.text.strip()])\n",
    "        if len(extracted_text) > 500:\n",
    "            return extracted_text\n",
    "\n",
    "        soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "        paragraphs = soup.find_all(\"p\")\n",
    "        extracted_text = \"\\n\".join([p.get_text() for p in paragraphs])\n",
    "        return extracted_text if len(extracted_text) > 500 else \"Content could not be extracted.\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error extracting content: {str(e)}\"\n",
    "\n",
    "# ‚úÖ Fetch & Process News\n",
    "response = requests.get(BASE_URL)\n",
    "news_data = response.json().get(\"data\", [])[:MAX_ARTICLES]\n",
    "\n",
    "articles_list = []\n",
    "for i, article in enumerate(news_data):\n",
    "    url = article.get(\"url\", \"\")\n",
    "    \n",
    "    if not url or is_paywalled(url):\n",
    "        print(f\"üö´ Skipping paywalled article: {url}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"üîç [{i+1}/{MAX_ARTICLES}] Processing: {url}\")\n",
    "    full_text = extract_full_text(url)\n",
    "\n",
    "    articles_list.append({\n",
    "        \"title\": article.get(\"title\", \"Unknown title\"),\n",
    "        \"url\": url,\n",
    "        \"published_date\": article.get(\"published_at\", \"Unknown date\"),\n",
    "        \"source_name\": article[\"source\"][\"name\"] if isinstance(article.get(\"source\"), dict) else \"Unknown source\",\n",
    "        \"author\": article[\"author\"] if isinstance(article.get(\"author\"), str) else \"Unknown author\",\n",
    "        \"category\": article[\"category\"] if isinstance(article.get(\"category\"), str) else \"Unknown category\",\n",
    "        \"content\": full_text\n",
    "    })\n",
    "    time.sleep(2)  # Avoid API rate limits\n",
    "\n",
    "# ‚úÖ Save Archived JSON File\n",
    "date_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "filename = f\"news_{date_str}.json\"\n",
    "filepath = os.path.join(NEWS_DIR, filename)\n",
    "\n",
    "with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(articles_list, f, indent=4)\n",
    "\n",
    "print(f\"‚úÖ {len(articles_list)} articles saved in '{filepath}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ChromaDB instance found. Using existing database.\n",
      "‚úÖ Collection 'news_articles' exists.\n",
      "‚úÖ ChromaDB is ready to use.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import chromadb\n",
    "\n",
    "# ‚úÖ ChromaDB Path\n",
    "CHROMA_DB_PATH = \"../chroma_db\"\n",
    "\n",
    "# ‚úÖ Ensure ChromaDB Exists\n",
    "if not os.path.exists(CHROMA_DB_PATH):\n",
    "    print(\"‚ö†Ô∏è ChromaDB instance not found. Creating a new one...\")\n",
    "    os.makedirs(CHROMA_DB_PATH)  \n",
    "else:\n",
    "    print(\"‚úÖ ChromaDB instance found. Using existing database.\")\n",
    "\n",
    "# ‚úÖ Initialize Client & Collection\n",
    "client = chromadb.PersistentClient(path=CHROMA_DB_PATH)\n",
    "collection_name = \"news_articles\"\n",
    "\n",
    "try:\n",
    "    collection = client.get_collection(collection_name)\n",
    "    print(f\"‚úÖ Collection '{collection_name}' exists.\")\n",
    "except Exception:\n",
    "    print(f\"‚ö†Ô∏è Collection '{collection_name}' not found. Creating a new one...\")\n",
    "    collection = client.create_collection(collection_name)\n",
    "\n",
    "print(f\"‚úÖ ChromaDB is ready to use.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Entries to ChromaDB from the newly generated news.json file and archiving it\n",
    "\n",
    "It checks for the most recent file from NEWS_FILES directory\n",
    "- Toggle if you wish to check all files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processing ALL 4 news files in NEWS_FILES\n",
      "‚úÖ Loaded 9 articles from news_001_2025-02-17.json.\n",
      "‚úÖ Loaded 49 articles from news_002_2025-02-17.json.\n",
      "‚úÖ Loaded 49 articles from news_003_2025-02-17.json.\n",
      "‚úÖ Loaded 10 articles from news_2025-02-17.json.\n"
     ]
    },
    {
     "ename": "DuplicateIDError",
     "evalue": "Expected IDs to be unique, found 39 duplicated IDs: https://www.kivitv.com/news/local-news/in-your-neighborhood/i-84-closures-from-pendleton-to-baker-city, https://www.slashgear.com/1783116/air-force-one-facts-features-amazing-presidential-aircraft-vc-25/, https://www.argophilia.com/news/diktaean-cave-still-closed/240400/, https://www.completesports.com/psg-man-united-table-verbal-contract-offers-for-osimhen/, https://www.koimoi.com/box-office/sanam-teri-kasam-re-release-box-office-bigger-hit-than-tere-naam-with-365-higher-profit-than-salman-khans-tragic-love-story/, ..., https://prowrestling.net/site/2025/02/17/tna-impact-preview-the-lineup-for-thursdays-live-show-full-sail-reports-needed-2/, https://247wallst.com/economy/2025/02/17/these-states-have-the-highest-foreclosure-rates-going-into-2025/, https://www.scotsman.com/news/scottish-news/scottish-museum-to-undergo-bold-transformation-after-ps26m-government-funding-boost-4994958, https://seekingalpha.com/article/4758990-could-nvidia-buck-the-trend-of-a-wider-market-downturn?source=feed_all_articles, https://www.dvidshub.net/image/8873839/2025-african-air-chiefs-symposium-commences-with-opening-ceremony in add.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDuplicateIDError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\newpc\\Documents\\Spiced\\FakeBuster\\FakeBuster\\.venv\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:90\u001b[0m, in \u001b[0;36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\newpc\\Documents\\Spiced\\FakeBuster\\FakeBuster\\.venv\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:207\u001b[0m, in \u001b[0;36mCollectionCommon._validate_and_prepare_add_request\u001b[1;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[1;32m--> 207\u001b[0m \u001b[43mvalidate_insert_record_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_records\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    208\u001b[0m validate_record_set_contains_any(record_set\u001b[38;5;241m=\u001b[39madd_records, contains_any\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "File \u001b[1;32mc:\\Users\\newpc\\Documents\\Spiced\\FakeBuster\\FakeBuster\\.venv\\Lib\\site-packages\\chromadb\\api\\types.py:228\u001b[0m, in \u001b[0;36mvalidate_insert_record_set\u001b[1;34m(record_set)\u001b[0m\n\u001b[0;32m    226\u001b[0m validate_base_record_set(record_set)\n\u001b[1;32m--> 228\u001b[0m \u001b[43mvalidate_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m record_set[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadatas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\newpc\\Documents\\Spiced\\FakeBuster\\FakeBuster\\.venv\\Lib\\site-packages\\chromadb\\api\\types.py:531\u001b[0m, in \u001b[0;36mvalidate_ids\u001b[1;34m(ids)\u001b[0m\n\u001b[0;32m    530\u001b[0m         message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected IDs to be unique, found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_dups\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m duplicated IDs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexample_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 531\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mDuplicateIDError(message)\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ids\n",
      "\u001b[1;31mDuplicateIDError\u001b[0m: Expected IDs to be unique, found 39 duplicated IDs: https://www.kivitv.com/news/local-news/in-your-neighborhood/i-84-closures-from-pendleton-to-baker-city, https://www.slashgear.com/1783116/air-force-one-facts-features-amazing-presidential-aircraft-vc-25/, https://www.argophilia.com/news/diktaean-cave-still-closed/240400/, https://www.completesports.com/psg-man-united-table-verbal-contract-offers-for-osimhen/, https://www.koimoi.com/box-office/sanam-teri-kasam-re-release-box-office-bigger-hit-than-tere-naam-with-365-higher-profit-than-salman-khans-tragic-love-story/, ..., https://prowrestling.net/site/2025/02/17/tna-impact-preview-the-lineup-for-thursdays-live-show-full-sail-reports-needed-2/, https://247wallst.com/economy/2025/02/17/these-states-have-the-highest-foreclosure-rates-going-into-2025/, https://www.scotsman.com/news/scottish-news/scottish-museum-to-undergo-bold-transformation-after-ps26m-government-funding-boost-4994958, https://seekingalpha.com/article/4758990-could-nvidia-buck-the-trend-of-a-wider-market-downturn?source=feed_all_articles, https://www.dvidshub.net/image/8873839/2025-african-air-chiefs-symposium-commences-with-opening-ceremony",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mDuplicateIDError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 60\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# ‚úÖ Store in ChromaDB\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_entries:\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mcollection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mentry\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdocument\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mentry\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnew_entries\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mentry\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mentry\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnew_entries\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mentry\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mentry\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnew_entries\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mentry\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membedding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mentry\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnew_entries\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(new_entries)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m new articles added to ChromaDB.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\newpc\\Documents\\Spiced\\FakeBuster\\FakeBuster\\.venv\\Lib\\site-packages\\chromadb\\api\\models\\Collection.py:82\u001b[0m, in \u001b[0;36mCollection.add\u001b[1;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21madd\u001b[39m(\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     49\u001b[0m     ids: OneOrMany[ID],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m     uris: Optional[OneOrMany[URI]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     60\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Add embeddings to the data store.\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;124;03m        ids: The ids of the embeddings you wish to add\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     79\u001b[0m \n\u001b[0;32m     80\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m     add_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_and_prepare_add_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43muris\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muris\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_add(\n\u001b[0;32m     92\u001b[0m         collection_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid,\n\u001b[0;32m     93\u001b[0m         ids\u001b[38;5;241m=\u001b[39madd_request[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     99\u001b[0m         database\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatabase,\n\u001b[0;32m    100\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\newpc\\Documents\\Spiced\\FakeBuster\\FakeBuster\\.venv\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:93\u001b[0m, in \u001b[0;36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     92\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(msg)\u001b[38;5;241m.\u001b[39mwith_traceback(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\newpc\\Documents\\Spiced\\FakeBuster\\FakeBuster\\.venv\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:90\u001b[0m, in \u001b[0;36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m: Any, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 90\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     92\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\newpc\\Documents\\Spiced\\FakeBuster\\FakeBuster\\.venv\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:207\u001b[0m, in \u001b[0;36mCollectionCommon._validate_and_prepare_add_request\u001b[1;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[0m\n\u001b[0;32m    197\u001b[0m add_records \u001b[38;5;241m=\u001b[39m normalize_insert_record_set(\n\u001b[0;32m    198\u001b[0m     ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[0;32m    199\u001b[0m     embeddings\u001b[38;5;241m=\u001b[39membeddings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    203\u001b[0m     uris\u001b[38;5;241m=\u001b[39muris,\n\u001b[0;32m    204\u001b[0m )\n\u001b[0;32m    206\u001b[0m \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[1;32m--> 207\u001b[0m \u001b[43mvalidate_insert_record_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_records\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    208\u001b[0m validate_record_set_contains_any(record_set\u001b[38;5;241m=\u001b[39madd_records, contains_any\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m    210\u001b[0m \u001b[38;5;66;03m# Prepare\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\newpc\\Documents\\Spiced\\FakeBuster\\FakeBuster\\.venv\\Lib\\site-packages\\chromadb\\api\\types.py:228\u001b[0m, in \u001b[0;36mvalidate_insert_record_set\u001b[1;34m(record_set)\u001b[0m\n\u001b[0;32m    225\u001b[0m _validate_record_set_length_consistency(record_set)\n\u001b[0;32m    226\u001b[0m validate_base_record_set(record_set)\n\u001b[1;32m--> 228\u001b[0m \u001b[43mvalidate_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m record_set[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadatas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    230\u001b[0m     validate_metadatas(record_set[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadatas\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\newpc\\Documents\\Spiced\\FakeBuster\\FakeBuster\\.venv\\Lib\\site-packages\\chromadb\\api\\types.py:531\u001b[0m, in \u001b[0;36mvalidate_ids\u001b[1;34m(ids)\u001b[0m\n\u001b[0;32m    527\u001b[0m         example_string \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    528\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(examples[:\u001b[38;5;241m5\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, ..., \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(examples[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m:])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    529\u001b[0m         )\n\u001b[0;32m    530\u001b[0m         message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected IDs to be unique, found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_dups\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m duplicated IDs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexample_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 531\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mDuplicateIDError(message)\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ids\n",
      "\u001b[1;31mDuplicateIDError\u001b[0m: Expected IDs to be unique, found 39 duplicated IDs: https://www.kivitv.com/news/local-news/in-your-neighborhood/i-84-closures-from-pendleton-to-baker-city, https://www.slashgear.com/1783116/air-force-one-facts-features-amazing-presidential-aircraft-vc-25/, https://www.argophilia.com/news/diktaean-cave-still-closed/240400/, https://www.completesports.com/psg-man-united-table-verbal-contract-offers-for-osimhen/, https://www.koimoi.com/box-office/sanam-teri-kasam-re-release-box-office-bigger-hit-than-tere-naam-with-365-higher-profit-than-salman-khans-tragic-love-story/, ..., https://prowrestling.net/site/2025/02/17/tna-impact-preview-the-lineup-for-thursdays-live-show-full-sail-reports-needed-2/, https://247wallst.com/economy/2025/02/17/these-states-have-the-highest-foreclosure-rates-going-into-2025/, https://www.scotsman.com/news/scottish-news/scottish-museum-to-undergo-bold-transformation-after-ps26m-government-funding-boost-4994958, https://seekingalpha.com/article/4758990-could-nvidia-buck-the-trend-of-a-wider-market-downturn?source=feed_all_articles, https://www.dvidshub.net/image/8873839/2025-african-air-chiefs-symposium-commences-with-opening-ceremony in add."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ‚úÖ CONFIGURATION\n",
    "NEWS_DIR = \"NEWS_FILES\"\n",
    "check_all_files = True  # Toggle: True to check all files, False to only process the latest file\n",
    "\n",
    "# ‚úÖ Get Files to Process\n",
    "if check_all_files:\n",
    "    news_files = sorted(os.listdir(NEWS_DIR))  # Get all files\n",
    "    print(f\"üîç Processing ALL {len(news_files)} news files in {NEWS_DIR}\")\n",
    "else:\n",
    "    news_files = [sorted(os.listdir(NEWS_DIR))[-1]]  # Get only the most recent file\n",
    "    print(f\"üîç Processing LATEST file: {news_files[0]}\")\n",
    "\n",
    "# ‚úÖ Load Embedding Model\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# ‚úÖ Avoid Duplicate Entries in ChromaDB\n",
    "existing_ids = set(collection.get()[\"ids\"])\n",
    "new_entries = []\n",
    "\n",
    "# ‚úÖ Process Each File\n",
    "for news_file in news_files:\n",
    "    news_filepath = os.path.join(NEWS_DIR, news_file)\n",
    "\n",
    "    try:\n",
    "        with open(news_filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            articles_list = json.load(f)\n",
    "\n",
    "        print(f\"‚úÖ Loaded {len(articles_list)} articles from {news_file}.\")\n",
    "\n",
    "        # ‚úÖ Process Articles\n",
    "        for article in articles_list:\n",
    "            article_id = article[\"url\"]\n",
    "            if article_id not in existing_ids:  # Avoid duplicates\n",
    "                text = f\"{article['title']} {article['content']}\"\n",
    "                embedding = embedding_model.encode(text).tolist()\n",
    "\n",
    "                new_entries.append({\n",
    "                    \"document\": text,\n",
    "                    \"metadata\": {\n",
    "                        \"title\": article[\"title\"],\n",
    "                        \"url\": article[\"url\"],\n",
    "                        \"published_date\": article[\"published_date\"],\n",
    "                        \"source_name\": article[\"source_name\"],\n",
    "                        \"author\": article[\"author\"],\n",
    "                        \"category\": article[\"category\"]\n",
    "                    },\n",
    "                    \"id\": article_id,\n",
    "                    \"embedding\": embedding\n",
    "                })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error processing {news_file}: {str(e)}\")\n",
    "\n",
    "# ‚úÖ Store in ChromaDB\n",
    "if new_entries:\n",
    "    collection.add(\n",
    "        documents=[entry[\"document\"] for entry in new_entries],\n",
    "        metadatas=[entry[\"metadata\"] for entry in new_entries],\n",
    "        ids=[entry[\"id\"] for entry in new_entries],\n",
    "        embeddings=[entry[\"embedding\"] for entry in new_entries]\n",
    "    )\n",
    "    print(f\"‚úÖ {len(new_entries)} new articles added to ChromaDB.\")\n",
    "else:\n",
    "    print(\"üîπ No new articles added. Database is up to date.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
