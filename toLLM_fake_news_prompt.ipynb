{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸš€ Fake News Detection Prompt Optimization\n",
    "\n",
    "The goal of Fake News Detection Prompt Optimization is to improve the effectiveness of the LLMâ€™s response by: \\\n",
    "âœ… Providing structured context from RAG \\\n",
    "âœ… Clearly defining the linguistic analysis metrics used \\\n",
    "âœ… Guiding the LLM to make well-reasoned credibility assessments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ“Œ Script: Formatting a RAG-to-LLM Prompt for Fake News Detection\n",
    "\n",
    "This script structures the prompt sent to the LLM, ensuring it understands: \\\n",
    "ğŸ”¹ The original news article \\\n",
    "ğŸ”¹ The linguistic analysis results (TF-IDF outliers, sentiment, readability, etc.) \\\n",
    "ğŸ”¹ Fact-checking guidance (what the LLM should evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def format_fake_news_prompt(article):\n",
    "    \"\"\"\n",
    "    Formats a structured prompt for LLM fake news detection.\n",
    "    The prompt includes RAG-retrieved context, linguistic analysis, and evaluation instructions.\n",
    "    \"\"\"\n",
    "\n",
    "    # âœ… Extract Key Article Information\n",
    "    title = article[\"title\"]\n",
    "    url = article[\"url\"]\n",
    "    published_date = article.get(\"published_date\", \"Unknown date\")\n",
    "    source_name = article.get(\"source_name\", \"Unknown source\")\n",
    "    author = article.get(\"author\", \"Unknown author\")\n",
    "    category = article.get(\"category\", \"Unknown category\")\n",
    "    content = article[\"content\"]\n",
    "\n",
    "    # âœ… Extract Linguistic Analysis\n",
    "    linguistic_analysis = article[\"linguistic_analysis\"]\n",
    "    summary = linguistic_analysis.get(\"summary\", \"No summary available.\")\n",
    "    tfidf_outliers = \", \".join(linguistic_analysis[\"tfidf_outliers\"])\n",
    "    grammar_errors = linguistic_analysis[\"grammar_errors\"]\n",
    "    sentence_count = linguistic_analysis[\"sentence_count\"]\n",
    "    sentiment_polarity = linguistic_analysis[\"sentiment_polarity\"]\n",
    "    sentiment_subjectivity = linguistic_analysis[\"sentiment_subjectivity\"]\n",
    "\n",
    "    # âœ… Construct Prompt\n",
    "    prompt = f\"\"\"\n",
    "    You are a fact-checking AI analyzing the credibility of a news article. Below is the structured information:\n",
    "    \n",
    "    ğŸ“° **Article Information:**\n",
    "    - **Title:** {title}\n",
    "    - **URL:** {url}\n",
    "    - **Published Date:** {published_date}\n",
    "    - **Source:** {source_name}\n",
    "    - **Author:** {author}\n",
    "    - **Category:** {category}\n",
    "\n",
    "    ğŸ”¹ **Article Summary (Generated via BERT):**\n",
    "    \"{summary}\"\n",
    "\n",
    "    ğŸ“Š **Linguistic Analysis:**\n",
    "    - **TF-IDF Outlier Keywords (Unique/Unusual Words):** {tfidf_outliers}\n",
    "    - **Grammar Issues:** {grammar_errors} errors\n",
    "    - **Sentence Count:** {sentence_count}\n",
    "    - **Sentiment Analysis:** \n",
    "        - **Polarity (Scale -1 to 1):** {sentiment_polarity}\n",
    "        - **Subjectivity (Scale 0 to 1, higher = opinionated):** {sentiment_subjectivity}\n",
    "\n",
    "    ğŸ¯ **Your Task:**\n",
    "    1ï¸âƒ£ **Assess the credibility of this article** based on the provided content and linguistic analysis.  \n",
    "    2ï¸âƒ£ **Use the TF-IDF outlier words** to determine if the article contains **unusual phrasing or misleading language.**  \n",
    "    3ï¸âƒ£ **Analyze sentiment:** Does the emotional tone suggest bias, fear-mongering, or objectivity?  \n",
    "    4ï¸âƒ£ **Evaluate readability & grammar:** Is the article professionally written, or does it contain errors typical of misinformation?  \n",
    "    5ï¸âƒ£ **Compare against reliable sources** if possible, to determine factual accuracy.  \n",
    "\n",
    "    ğŸ† **Final Response Format:**\n",
    "    - **Credibility Score:** (Scale 0-100, where 100 = totally credible, 0 = completely false)\n",
    "    - **Verdict:** (Choose one: \"True\", \"False\", or \"Misleading\")\n",
    "    - **Explanation:** (2-3 sentences summarizing why you assigned this rating)\n",
    "    \"\"\"\n",
    "\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ“ How This Improves Fake News Detection Prompts\n",
    "\n",
    "âœ… Structured Information â†’ The LLM gets article metadata + analysis results clearly.\n",
    "âœ… Contextual Guidance â†’ The LLM knows what to check (keywords, sentiment, grammar).\n",
    "âœ… Standardized Response Format â†’ Ensures consistent evaluation across articles.\n",
    "âœ… Fact-Checking Instructions â†’ LLM is instructed to verify against known sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ“° **Article Information:**\n",
    "- **Title:** \"NASA to Launch Mission to Mars in 2025\"\n",
    "- **URL:** https://example.com/nasa-mars-mission\n",
    "- **Published Date:** February 12, 2024\n",
    "- **Source:** SpaceNews\n",
    "- **Author:** John Doe\n",
    "- **Category:** Science\n",
    "\n",
    "ğŸ”¹ **Article Summary (Generated via BERT):**\n",
    "\"NASA has announced a mission to Mars in 2025, with plans to deploy a new rover for data collection.\"\n",
    "\n",
    "ğŸ“Š **Linguistic Analysis:**\n",
    "- **TF-IDF Outlier Keywords:** \"Mars2025, deep-space, propulsion, roverX\"\n",
    "- **Grammar Issues:** 3 errors\n",
    "- **Sentence Count:** 24\n",
    "- **Sentiment Analysis:**\n",
    "    - **Polarity:** 0.2 (Neutral)\n",
    "    - **Subjectivity:** 0.4 (Moderately Objective)\n",
    "\n",
    "ğŸ¯ **Your Task:**\n",
    "1ï¸âƒ£ **Assess credibility** based on linguistic and factual analysis.  \n",
    "2ï¸âƒ£ **Check TF-IDF words** for unusual terminology.  \n",
    "3ï¸âƒ£ **Analyze sentiment & grammar.**  \n",
    "4ï¸âƒ£ **Compare against known sources.**  \n",
    "\n",
    "ğŸ† **Final Response Format:**\n",
    "- **Credibility Score:** (Scale 0-100)\n",
    "- **Verdict:** \"True\" / \"False\" / \"Misleading\"\n",
    "- **Explanation:** 2-3 sentences\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps for Refinement:\n",
    "Task\t ------------  Improvement \\\n",
    "âœ… Test Prompt Variations -- Try different instruction formats to see which generates the best LLM responses. \\\n",
    "âœ… Expand Fact-Checking Instructions\t-- Include reliable sources for LLM verification (e.g., Snopes, FactCheck.org). \\\n",
    "âœ… Track LLM Response Quality -- Store LLM-generated credibility scores in ChromaDB for further analysis. \\\n",
    "âœ… Incorporate External Knowledge -- Augment with retrieved facts from Google Fact Check API before LLM evaluation. \\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸš€ Final Thoughts\n",
    "\n",
    "This optimized prompt ensures the LLM receives high-quality, structured input, improving the accuracy and consistency of fake news detection. By integrating linguistic analysis + RAG context, we enhance factual verification while ensuring scalable, structured AI fact-checking.\n",
    "\n",
    "ğŸ”¥ Now ready to test and iterate! ğŸš€ğŸ”¥"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
