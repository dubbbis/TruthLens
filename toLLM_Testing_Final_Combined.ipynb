{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FACT-CHECKING PROMPT (**PROMPT ENGINEERING**)\n",
    "#### 01. PROMPT_05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import json\n",
    "\n",
    "def construct_fact_checking_prompt(enriched_entry):\n",
    "    \"\"\"\n",
    "    Constructs a well-formatted prompt for fact-checking using DeepSeek LLM.\n",
    "    \n",
    "    Args:\n",
    "        enriched_entry (dict): A dictionary containing article metadata, enriched content, and linguistic analysis.\n",
    "    \n",
    "    Returns:\n",
    "        str: A formatted string prompt for the LLM.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract relevant fields from enriched_entry\n",
    "    title = enriched_entry.get(\"title\", \"Unknown Title\")\n",
    "    url = enriched_entry.get(\"url\", \"Unknown URL\")\n",
    "    published_date = enriched_entry.get(\"published_date\", \"Unknown Date\")\n",
    "    source_name = enriched_entry.get(\"source\", \"Unknown Source\")\n",
    "    author = enriched_entry.get(\"author\", \"Unknown Author\")\n",
    "    category = enriched_entry.get(\"category\", \"Unknown Category\")\n",
    "    summary = enriched_entry.get(\"enriched_content\", \"No summary available\")[:500]  # Truncate if too long\n",
    "    \n",
    "    tfidf_outliers = json.loads(enriched_entry.get(\"TF-IDF Outliers\", \"[]\"))  # Convert back to list\n",
    "    tfidf_outliers_str = \", \".join(tfidf_outliers) if tfidf_outliers else \"None\"\n",
    "    \n",
    "    grammar_errors = enriched_entry.get(\"Grammar Errors\", 0)\n",
    "    sentence_count = enriched_entry.get(\"Sentence Count\", 0)\n",
    "    sentiment_polarity = enriched_entry.get(\"Sentiment Polarity\", \"Unknown\")\n",
    "    sentiment_subjectivity = enriched_entry.get(\"Sentiment Subjectivity\", \"Unknown\")\n",
    "    fact_checking_summary = enriched_entry.get(\"fact_checking_summary\", \"No fact-checking data available.\")\n",
    "\n",
    "\n",
    "    # Construct the prompt_05\n",
    "    prompt = f\"\"\"\n",
    "    You are a fact-checking AI analyzing the credibility of a news article. Below is the structured information:\n",
    "    \n",
    "    üì∞ **Article Information:**\n",
    "    - **Title:** {title}\n",
    "    - **URL:** {url}\n",
    "    - **Published Date:** {published_date}\n",
    "    - **Source:** {source_name}\n",
    "    - **Author:** {author}\n",
    "    - **Category:** {category}\n",
    "\n",
    "    üîπ **Article Summary (Extracted via AI):**\n",
    "    \"{summary}\"\n",
    "    \n",
    "    üìä **Linguistic Analysis:**\n",
    "    - **TF-IDF Outlier Keywords (Unique/Unusual Words):** {tfidf_outliers_str}\n",
    "    - **Grammar Issues:** {grammar_errors} errors\n",
    "    - **Sentence Count:** {sentence_count}\n",
    "    - **Sentiment Analysis:** \n",
    "        - **Polarity (Scale -1 to 1):** {sentiment_polarity}\n",
    "        - **Subjectivity (Scale 0 to 1, higher = opinionated):** {sentiment_subjectivity}\n",
    "\n",
    "    üéØ **Your Task:**\n",
    "    1Ô∏è‚É£ **Assess the credibility of this article** based on the provided content and linguistic analysis.  \n",
    "    2Ô∏è‚É£ **Use the TF-IDF outlier words** to determine if the article contains **unusual phrasing or misleading language.**  \n",
    "    3Ô∏è‚É£ **Analyze sentiment:** Does the emotional tone suggest bias, fear-mongering, or objectivity?  \n",
    "    4Ô∏è‚É£ **Evaluate readability & grammar:** Is the article professionally written, or does it contain errors typical of misinformation?  \n",
    "    5Ô∏è‚É£ **Compare against reliable sources** if possible, to determine factual accuracy.  \n",
    "    \n",
    "    üèÜ **Final Response Format:**\n",
    "    - **Credibility Score:** (Scale 0-100, where 100 = totally credible, 0 = completely false)\n",
    "    - **Verdict:** (Choose one: \"True\", \"False\", or \"Misleading\")\n",
    "    - **Explanation:** (2-3 sentences summarizing why you assigned this rating)\n",
    "    \"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "example_entry = {\n",
    "    \"title\": \"Breaking News: AI Solves World Hunger\",\n",
    "    \"url\": \"https://news.example.com/ai-hunger\",\n",
    "    \"published_date\": \"2025-02-18\",\n",
    "    \"source\": \"Example News\",\n",
    "    \"author\": \"John Doe\",\n",
    "    \"category\": \"Technology\",\n",
    "    \"enriched_content\": \"AI has made significant advancements... (summary content here)...\\n\\nFact-Checking Data:\\n- Verified by multiple sources\",\n",
    "    \"TF-IDF Outliers\": json.dumps([\"AI\", \"breakthrough\", \"hunger crisis\"]),\n",
    "    \"Grammar Errors\": 2,\n",
    "    \"Sentence Count\": 25,\n",
    "    \"Sentiment Polarity\": 0.7,\n",
    "    \"Sentiment Subjectivity\": 0.4,\n",
    "    \"fact_checking_summary\": \"Verified by multiple sources.\"\n",
    "}\n",
    "\n",
    "# Generate the prompt\n",
    "prompt_text = construct_fact_checking_prompt(example_entry)\n",
    "print(prompt_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 02. PROMPT_06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import json\n",
    "\n",
    "def construct_fact_checking_prompt(enriched_entry):\n",
    "    \"\"\"\n",
    "    Constructs a well-formatted prompt for fact-checking using DeepSeek LLM.\n",
    "    \n",
    "    Args:\n",
    "        enriched_entry (dict): A dictionary containing article metadata, enriched content, and linguistic analysis.\n",
    "    \n",
    "    Returns:\n",
    "        str: A formatted string prompt for the LLM.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract relevant fields from enriched_entry\n",
    "    title = enriched_entry.get(\"title\", \"Unknown Title\")\n",
    "    url = enriched_entry.get(\"url\", \"Unknown URL\")\n",
    "    published_date = enriched_entry.get(\"published_date\", \"Unknown Date\")\n",
    "    source_name = enriched_entry.get(\"source\", \"Unknown Source\")\n",
    "    author = enriched_entry.get(\"author\", \"Unknown Author\")\n",
    "    category = enriched_entry.get(\"category\", \"Unknown Category\")\n",
    "    summary = enriched_entry.get(\"enriched_content\", \"No summary available\")[:500]  # Truncate if too long\n",
    "    \n",
    "    tfidf_outliers = json.loads(enriched_entry.get(\"TF-IDF Outliers\", \"[]\"))  # Convert back to list\n",
    "    tfidf_outliers_str = \", \".join(tfidf_outliers) if tfidf_outliers else \"None\"\n",
    "    \n",
    "    grammar_errors = enriched_entry.get(\"Grammar Errors\", 0)\n",
    "    sentence_count = enriched_entry.get(\"Sentence Count\", 0)\n",
    "    sentiment_polarity = enriched_entry.get(\"Sentiment Polarity\", \"Unknown\")\n",
    "    sentiment_subjectivity = enriched_entry.get(\"Sentiment Subjectivity\", \"Unknown\")\n",
    "    fact_checking_summary = enriched_entry.get(\"fact_checking_summary\", \"No fact-checking data available.\")\n",
    "\n",
    "\n",
    "    \n",
    "  # Construct the prompt_06\n",
    "    prompt = f\"\"\"\n",
    "    You are a fact-checking AI analyzing the credibility of a news article. Below is the structured information:\n",
    "    \n",
    "    üì∞ **Article Information:**\n",
    "    - **Title:** {title}\n",
    "    - **URL:** {url}\n",
    "    - **Published Date:** {published_date}\n",
    "    - **Source:** {source_name}\n",
    "    - **Author:** {author}\n",
    "    - **Category:** {category}\n",
    "\n",
    "    üîπ **Article Summary (Extracted via AI):**\n",
    "    \"{summary}\"\n",
    "    \n",
    "    üìä **Linguistic Analysis:**\n",
    "    - **TF-IDF Outlier Keywords (Unique/Unusual Words):** {tfidf_outliers_str}\n",
    "    - **Grammar Issues:** {grammar_errors} errors\n",
    "    - **Sentence Count:** {sentence_count}\n",
    "    - **Sentiment Analysis:** \n",
    "        - **Polarity (Scale -1 to 1):** {sentiment_polarity}\n",
    "        - **Subjectivity (Scale 0 to 1, higher = opinionated):** {sentiment_subjectivity}\n",
    "\n",
    " ## üéØ Task: Evaluate Credibility and Truthfulness  \n",
    "    Based on the provided information, conduct a critical analysis following these points:  \n",
    "\n",
    "    1Ô∏è‚É£ **Credibility Assessment:**  \n",
    "       - Is the source reliable?  \n",
    "       - Does the author have legitimate or recognized credentials in the field?  \n",
    "       - Does the article follow a logical and professional structure, or does it appear poorly written?  \n",
    "\n",
    "    2Ô∏è‚É£ **Detection of Misleading or Sensationalist Language:**  \n",
    "       - Analyze the unusual words detected by TF-IDF. Are these terms uncommon in serious journalism?  \n",
    "       - Does the article use exaggerated language to manipulate the reader‚Äôs emotions?  \n",
    "\n",
    "    3Ô∏è‚É£ **Bias and Subjectivity:**  \n",
    "       - Does the content appear neutral, or does it attempt to influence the reader‚Äôs opinion?  \n",
    "       - Are there phrases that exaggerate, alarm, or contain subjective judgments?  \n",
    "\n",
    "    4Ô∏è‚É£ **Verification with Other Sources:**  \n",
    "       - If a key fact is mentioned, is there verifiable evidence from reliable sources?  \n",
    "       - Are there missing expert citations or solid references?  \n",
    "\n",
    "    5Ô∏è‚É£ **Linguistic Quality:**  \n",
    "       - Does the text contain unusual grammatical errors for legitimate news articles?  \n",
    "       - Does it appear to be an automatically generated or poorly translated text?  \n",
    "\n",
    "    ---  \n",
    "    \n",
    "    ## üìå **Expected Response Format**  \n",
    "    - **Credibility Score (0-100):** (100 = Fully credible, 0 = Completely false)  \n",
    "    - **Final Verdict:** (\"True\", \"False\", or \"Misleading\")  \n",
    "    - **Detailed Explanation (3-5 sentences):** Justify the evaluation based on findings.  \n",
    "\n",
    "    ‚ö†Ô∏è **If the information is insufficient, indicate that more context or additional sources are needed.**  \n",
    "    \"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "# Example Usage\n",
    "example_entry = {\n",
    "    \"title\": \"Breaking News: AI Solves World Hunger\",\n",
    "    \"url\": \"https://news.example.com/ai-hunger\",\n",
    "    \"published_date\": \"2025-02-18\",\n",
    "    \"source\": \"Example News\",\n",
    "    \"author\": \"John Doe\",\n",
    "    \"category\": \"Technology\",\n",
    "    \"enriched_content\": \"AI has made significant advancements... (summary content here)...\\n\\nFact-Checking Data:\\n- Verified by multiple sources\",\n",
    "    \"TF-IDF Outliers\": json.dumps([\"AI\", \"breakthrough\", \"hunger crisis\"]),\n",
    "    \"Grammar Errors\": 2,\n",
    "    \"Sentence Count\": 25,\n",
    "    \"Sentiment Polarity\": 0.7,\n",
    "    \"Sentiment Subjectivity\": 0.4,\n",
    "    \"fact_checking_summary\": \"Verified by multiple sources.\"\n",
    "}\n",
    "\n",
    "# Generate the prompt\n",
    "prompt_text = construct_fact_checking_prompt(example_entry)\n",
    "print(prompt_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 03. PROMPT_07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import json\n",
    "\n",
    "def construct_fact_checking_prompt(enriched_entry):\n",
    "    \"\"\"\n",
    "    Constructs a well-formatted prompt for fact-checking using DeepSeek LLM.\n",
    "    \n",
    "    Args:\n",
    "        enriched_entry (dict): A dictionary containing article metadata, enriched content, and linguistic analysis.\n",
    "    \n",
    "    Returns:\n",
    "        str: A formatted string prompt for the LLM.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract relevant fields from enriched_entry\n",
    "    title = enriched_entry.get(\"title\", \"Unknown Title\")\n",
    "    url = enriched_entry.get(\"url\", \"Unknown URL\")\n",
    "    published_date = enriched_entry.get(\"published_date\", \"Unknown Date\")\n",
    "    source_name = enriched_entry.get(\"source\", \"Unknown Source\")\n",
    "    author = enriched_entry.get(\"author\", \"Unknown Author\")\n",
    "    category = enriched_entry.get(\"category\", \"Unknown Category\")\n",
    "    summary = enriched_entry.get(\"enriched_content\", \"No summary available\")[:500]  # Truncate if too long\n",
    "    \n",
    "    tfidf_outliers = json.loads(enriched_entry.get(\"TF-IDF Outliers\", \"[]\"))  # Convert back to list\n",
    "    tfidf_outliers_str = \", \".join(tfidf_outliers) if tfidf_outliers else \"None\"\n",
    "    \n",
    "    grammar_errors = enriched_entry.get(\"Grammar Errors\", 0)\n",
    "    sentence_count = enriched_entry.get(\"Sentence Count\", 0)\n",
    "    sentiment_polarity = enriched_entry.get(\"Sentiment Polarity\", \"Unknown\")\n",
    "    sentiment_subjectivity = enriched_entry.get(\"Sentiment Subjectivity\", \"Unknown\")\n",
    "    fact_checking_summary = enriched_entry.get(\"fact_checking_summary\", \"No fact-checking data available.\")\n",
    "\n",
    "\n",
    "    \n",
    "  # Construct the prompt_07\n",
    "    prompt = f\"\"\"\n",
    "    You are a fact-checking AI analyzing the credibility of a news article. Below is the structured information:\n",
    "    \n",
    "    üì∞ **Article Information:**\n",
    "    - **Title:** {title}\n",
    "    - **URL:** {url}\n",
    "    - **Published Date:** {published_date}\n",
    "    - **Source:** {source_name}\n",
    "    - **Author:** {author}\n",
    "    - **Category:** {category}\n",
    "\n",
    "    üîπ **Article Summary (Extracted via AI):**\n",
    "    \"{summary}\"\n",
    "    \n",
    "    üìä **Linguistic Analysis:**\n",
    "    - **TF-IDF Outlier Keywords (Unique/Unusual Words):** {tfidf_outliers_str}\n",
    "    - **Grammar Issues:** {grammar_errors} errors\n",
    "    - **Sentence Count:** {sentence_count}\n",
    "    - **Sentiment Analysis:** \n",
    "        - **Polarity (Scale -1 to 1):** {sentiment_polarity}\n",
    "        - **Subjectivity (Scale 0 to 1, higher = opinionated):** {sentiment_subjectivity}\n",
    "\n",
    " ## üéØ  Task: Evaluate Credibility and Truthfulness\n",
    "    Based on the provided information, conduct a critical analysis following these detailed tasks:\n",
    "\n",
    "    1. Source Credibility Analysis:\n",
    "       - Assess the reliability of the source and its reputation in journalism.\n",
    "       - Identify any potential conflicts of interest or biases within the source.\n",
    "       - Determine if the author has known expertise or credentials in the subject matter.\n",
    "\n",
    "    2. Content Verification:\n",
    "       - Cross-check key claims with verifiable and authoritative sources.\n",
    "       - Identify any exaggerations, misleading statements, or unverified claims.\n",
    "       - Evaluate if the article presents evidence and factual backing for its assertions.\n",
    "\n",
    "    3. Detection of Misleading or Sensationalist Language:\n",
    "       - Analyze the tone and wording of the article to identify emotional manipulation.\n",
    "       - Assess the presence of exaggerated or alarmist phrases that may indicate bias.\n",
    "       - Determine whether the article includes balanced viewpoints or only presents one-sided perspectives.\n",
    "\n",
    "    4. Bias and Subjectivity Evaluation:\n",
    "       - Determine whether the article contains subjective language or ideological framing.\n",
    "       - Identify any patterns of bias based on the article's structure, language, and omitted information.\n",
    "       - Consider whether the article serves an agenda beyond objective reporting.\n",
    "\n",
    "    5. External Source Comparison:\n",
    "       - Check if other reputable news sources report on the same topic and whether their coverage aligns.\n",
    "       - Identify inconsistencies in reporting across different sources.\n",
    "       - Evaluate whether primary sources (official statements, research papers, etc.) support the claims made.\n",
    "\n",
    "    6. Quality of Writing and Presentation:\n",
    "       - Analyze the grammatical accuracy and coherence of the text.\n",
    "       - Identify any unusual phrasing that may indicate automatic content generation or poor translation.\n",
    "       - Determine if the article follows standard journalistic practices in terms of citations and formatting.\n",
    "\n",
    "    ---\n",
    "    \n",
    "    Expected Response Format:\n",
    "    - Credibility Score (0-100): (100 = Fully credible, 0 = Completely false)\n",
    "    - Final Verdict: (\"True\", \"False\", or \"Misleading\")\n",
    "    - Detailed Explanation (4-6 sentences): Justify the evaluation based on findings, referencing key factors from the analysis.\n",
    "\n",
    "    If the information is insufficient to determine credibility, specify what additional context or sources would be necessary to reach a conclusive assessment.\n",
    "    \"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "# Example Usage\n",
    "example_entry = {\n",
    "    \"title\": \"Breaking News: AI Solves World Hunger\",\n",
    "    \"url\": \"https://news.example.com/ai-hunger\",\n",
    "    \"published_date\": \"2025-02-18\",\n",
    "    \"source\": \"Example News\",\n",
    "    \"author\": \"John Doe\",\n",
    "    \"category\": \"Technology\",\n",
    "    \"enriched_content\": \"AI has made significant advancements... (summary content here)...\\n\\nFact-Checking Data:\\n- Verified by multiple sources\",\n",
    "    \"TF-IDF Outliers\": json.dumps([\"AI\", \"breakthrough\", \"hunger crisis\"]),\n",
    "    \"Grammar Errors\": 2,\n",
    "    \"Sentence Count\": 25,\n",
    "    \"Sentiment Polarity\": 0.7,\n",
    "    \"Sentiment Subjectivity\": 0.4,\n",
    "    \"fact_checking_summary\": \"Verified by multiple sources.\"\n",
    "}\n",
    "\n",
    "# Generate the prompt\n",
    "prompt_text = construct_fact_checking_prompt(example_entry)\n",
    "print(prompt_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04. PROMPT_08 (FINAL)\n",
    "I've enhanced the prompt by adding Chain-of-Thought reasoning and Few-Shot learning examples to guide the model in generating more accurate fact-checking responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    You are a fact-checking AI analyzing the credibility of a news article. Follow the structured process below to evaluate its reliability step by step.\n",
      "    \n",
      "    ## Article Information:\n",
      "    - **Title:** Breaking News: AI Solves World Hunger\n",
      "    - **URL:** https://news.example.com/ai-hunger\n",
      "    - **Published Date:** 2025-02-18\n",
      "    - **Source:** Example News\n",
      "    - **Author:** John Doe\n",
      "    - **Category:** Technology\n",
      "    \n",
      "    ## Article Summary (Extracted via AI):\n",
      "    \"AI has made significant advancements... (summary content here)...\n",
      "\n",
      "Fact-Checking Data:\n",
      "- Verified by multiple sources\"\n",
      "    \n",
      "    ## Linguistic Analysis:\n",
      "    - **TF-IDF Outlier Keywords (Unusual Terms):** AI, breakthrough, hunger crisis\n",
      "    - **Grammar Issues:** 2 errors\n",
      "    - **Sentence Count:** 25\n",
      "    - **Sentiment Analysis:**\n",
      "        - **Polarity (Scale -1 to 1):** 0.7\n",
      "        - **Subjectivity (Scale 0 to 1, where 1 = highly opinionated):** 0.4\n",
      "    \n",
      "    ---\n",
      "    \n",
      "    ## Step-by-Step Fact-Checking Process:\n",
      "    ### 1. Source Credibility Analysis\n",
      "    - Is the source reputable, unbiased, and known for accurate reporting?\n",
      "    - Does the author have expertise in this subject?\n",
      "    - Are there any known biases or conflicts of interest?\n",
      "    \n",
      "    ### 2. Content Verification\n",
      "    - Identify key factual claims in the article.\n",
      "    - Cross-check these claims with authoritative sources (official reports, academic papers, reputable news organizations).\n",
      "    - Are there missing citations or unverifiable claims?\n",
      "    \n",
      "    ### 3. Misleading or Sensationalist Language Detection\n",
      "    - Does the article use emotionally charged or manipulative language?\n",
      "    - Are there exaggerated statements, alarmist phrases, or one-sided narratives?\n",
      "    - Compare the tone to neutral, fact-based reporting.\n",
      "    \n",
      "    ### 4. Bias and Subjectivity Evaluation\n",
      "    - Assess if the article favors a particular viewpoint.\n",
      "    - Does it omit relevant facts that would provide a balanced perspective?\n",
      "    - Look for patterns of ideological framing.\n",
      "    \n",
      "    ### 5. External Source Comparison\n",
      "    - Are other reputable sources reporting on the same topic?\n",
      "    - If so, do their accounts align with this article?\n",
      "    - Are primary sources (official documents, expert opinions) cited and accurately represented?\n",
      "    \n",
      "    ### 6. Quality of Writing and Presentation\n",
      "    - Does the article follow proper journalistic standards?\n",
      "    - Are there spelling, grammar, or formatting issues that suggest a lack of editorial oversight?\n",
      "    - Is there evidence of automated content generation or poor translation?\n",
      "    \n",
      "    ---\n",
      "    \n",
      "    ## Expected Response Format (Use Chain-of-Thought Reasoning)\n",
      "    \n",
      "    ### Example Analysis (Few-Shot Learning Reference)\n",
      "    **Article Title:** \"Company XYZ Announces Revolutionary Cancer Treatment\"\n",
      "    \n",
      "    **Step 1 - Source Credibility:**\n",
      "    - The article is from \"HealthNewsNow.com,\" which is not a well-known medical journal.\n",
      "    - The author has no medical credentials.\n",
      "    \n",
      "    **Step 2 - Content Verification:**\n",
      "    - The claim that \"XYZ's drug cures cancer in 90% of cases\" is not supported by any clinical trial data.\n",
      "    - No references to peer-reviewed research were found.\n",
      "    \n",
      "    **Step 3 - Sensationalist Language:**\n",
      "    - The article repeatedly uses phrases like \"miracle cure\" and \"breakthrough,\" suggesting hype over factual accuracy.\n",
      "    \n",
      "    **Step 4 - Bias and Framing:**\n",
      "    - The piece heavily promotes the company's stock, indicating a financial motive.\n",
      "    \n",
      "    **Step 5 - External Source Comparison:**\n",
      "    - No major medical journals or regulatory agencies have published similar findings.\n",
      "    \n",
      "    **Step 6 - Writing Quality:**\n",
      "    - Several grammar errors and an informal tone reduce credibility.\n",
      "    \n",
      "    **Final Verdict:** \"Misleading\"\n",
      "    **Credibility Score:** 25/100\n",
      "    **Explanation:** The article lacks verifiable sources, contains promotional bias, and exaggerates claims without evidence.\n",
      "    \n",
      "    ---\n",
      "    \n",
      "    Now, apply this step-by-step method to the given article and provide your evaluation.\n",
      "    \n",
      "    **Final Expected Output:**\n",
      "    - **Credibility Score (0-100):** (100 = Fully credible, 0 = Completely false)\n",
      "    - **Final Verdict:** (\"True\", \"False\", or \"Misleading\")\n",
      "    - **Detailed Explanation (4-6 sentences)** referencing key findings from each fact-checking step.\n",
      "    - **If insufficient information is available, specify what additional sources or context are needed.**\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def construct_fact_checking_prompt(enriched_entry):\n",
    "    \"\"\"\n",
    "    Constructs a well-formatted prompt for fact-checking using DeepSeek LLM.\n",
    "    \n",
    "    Args:\n",
    "        enriched_entry (dict): A dictionary containing article metadata, enriched content, and linguistic analysis.\n",
    "    \n",
    "    Returns:\n",
    "        str: A formatted string prompt for the LLM.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract relevant fields from enriched_entry\n",
    "    title = enriched_entry.get(\"title\", \"Unknown Title\")\n",
    "    url = enriched_entry.get(\"url\", \"Unknown URL\")\n",
    "    published_date = enriched_entry.get(\"published_date\", \"Unknown Date\")\n",
    "    source_name = enriched_entry.get(\"source\", \"Unknown Source\")\n",
    "    author = enriched_entry.get(\"author\", \"Unknown Author\")\n",
    "    category = enriched_entry.get(\"category\", \"Unknown Category\")\n",
    "    summary = enriched_entry.get(\"enriched_content\", \"No summary available\")[:500]  # Truncate if too long\n",
    "    \n",
    "    tfidf_outliers = json.loads(enriched_entry.get(\"TF-IDF Outliers\", \"[]\"))  # Convert back to list\n",
    "    tfidf_outliers_str = \", \".join(tfidf_outliers) if tfidf_outliers else \"None\"\n",
    "    \n",
    "    grammar_errors = enriched_entry.get(\"Grammar Errors\", 0)\n",
    "    sentence_count = enriched_entry.get(\"Sentence Count\", 0)\n",
    "    sentiment_polarity = enriched_entry.get(\"Sentiment Polarity\", \"Unknown\")\n",
    "    sentiment_subjectivity = enriched_entry.get(\"Sentiment Subjectivity\", \"Unknown\")\n",
    "    fact_checking_summary = enriched_entry.get(\"fact_checking_summary\", \"No fact-checking data available.\")\n",
    "\n",
    "\n",
    "    \n",
    "  # Construct the prompt_08\n",
    "    prompt = f\"\"\"\n",
    "    You are a fact-checking AI analyzing the credibility of a news article. Follow the structured process below to evaluate its reliability step by step.\n",
    "    \n",
    "    ## Article Information:\n",
    "    - **Title:** {title}\n",
    "    - **URL:** {url}\n",
    "    - **Published Date:** {published_date}\n",
    "    - **Source:** {source_name}\n",
    "    - **Author:** {author}\n",
    "    - **Category:** {category}\n",
    "    \n",
    "    ## Article Summary (Extracted via AI):\n",
    "    \"{summary}\"\n",
    "    \n",
    "    ## Linguistic Analysis:\n",
    "    - **TF-IDF Outlier Keywords (Unusual Terms):** {tfidf_outliers_str}\n",
    "    - **Grammar Issues:** {grammar_errors} errors\n",
    "    - **Sentence Count:** {sentence_count}\n",
    "    - **Sentiment Analysis:**\n",
    "        - **Polarity (Scale -1 to 1):** {sentiment_polarity}\n",
    "        - **Subjectivity (Scale 0 to 1, where 1 = highly opinionated):** {sentiment_subjectivity}\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    ## Step-by-Step Fact-Checking Process:\n",
    "    ### 1. Source Credibility Analysis\n",
    "    - Is the source reputable, unbiased, and known for accurate reporting?\n",
    "    - Does the author have expertise in this subject?\n",
    "    - Are there any known biases or conflicts of interest?\n",
    "    \n",
    "    ### 2. Content Verification\n",
    "    - Identify key factual claims in the article.\n",
    "    - Cross-check these claims with authoritative sources (official reports, academic papers, reputable news organizations).\n",
    "    - Are there missing citations or unverifiable claims?\n",
    "    \n",
    "    ### 3. Misleading or Sensationalist Language Detection\n",
    "    - Does the article use emotionally charged or manipulative language?\n",
    "    - Are there exaggerated statements, alarmist phrases, or one-sided narratives?\n",
    "    - Compare the tone to neutral, fact-based reporting.\n",
    "    \n",
    "    ### 4. Bias and Subjectivity Evaluation\n",
    "    - Assess if the article favors a particular viewpoint.\n",
    "    - Does it omit relevant facts that would provide a balanced perspective?\n",
    "    - Look for patterns of ideological framing.\n",
    "    \n",
    "    ### 5. External Source Comparison\n",
    "    - Are other reputable sources reporting on the same topic?\n",
    "    - If so, do their accounts align with this article?\n",
    "    - Are primary sources (official documents, expert opinions) cited and accurately represented?\n",
    "    \n",
    "    ### 6. Quality of Writing and Presentation\n",
    "    - Does the article follow proper journalistic standards?\n",
    "    - Are there spelling, grammar, or formatting issues that suggest a lack of editorial oversight?\n",
    "    - Is there evidence of automated content generation or poor translation?\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    ## Expected Response Format (Use Chain-of-Thought Reasoning)\n",
    "    \n",
    "    ### Example Analysis (Few-Shot Learning Reference)\n",
    "    **Article Title:** \"Company XYZ Announces Revolutionary Cancer Treatment\"\n",
    "    \n",
    "    **Step 1 - Source Credibility:**\n",
    "    - The article is from \"HealthNewsNow.com,\" which is not a well-known medical journal.\n",
    "    - The author has no medical credentials.\n",
    "    \n",
    "    **Step 2 - Content Verification:**\n",
    "    - The claim that \"XYZ's drug cures cancer in 90% of cases\" is not supported by any clinical trial data.\n",
    "    - No references to peer-reviewed research were found.\n",
    "    \n",
    "    **Step 3 - Sensationalist Language:**\n",
    "    - The article repeatedly uses phrases like \"miracle cure\" and \"breakthrough,\" suggesting hype over factual accuracy.\n",
    "    \n",
    "    **Step 4 - Bias and Framing:**\n",
    "    - The piece heavily promotes the company's stock, indicating a financial motive.\n",
    "    \n",
    "    **Step 5 - External Source Comparison:**\n",
    "    - No major medical journals or regulatory agencies have published similar findings.\n",
    "    \n",
    "    **Step 6 - Writing Quality:**\n",
    "    - Several grammar errors and an informal tone reduce credibility.\n",
    "    \n",
    "    **Final Verdict:** \"Misleading\"\n",
    "    **Credibility Score:** 25/100\n",
    "    **Explanation:** The article lacks verifiable sources, contains promotional bias, and exaggerates claims without evidence.\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    Now, apply this step-by-step method to the given article and provide your evaluation.\n",
    "    \n",
    "    **Final Expected Output:**\n",
    "    - **Credibility Score (0-100):** (100 = Fully credible, 0 = Completely false)\n",
    "    - **Final Verdict:** (\"True\", \"False\", or \"Misleading\")\n",
    "    - **Detailed Explanation (4-6 sentences)** referencing key findings from each fact-checking step.\n",
    "    - **If insufficient information is available, specify what additional sources or context are needed.**\n",
    "    \"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "# Example Usage\n",
    "example_entry = {\n",
    "    \"title\": \"Breaking News: AI Solves World Hunger\",\n",
    "    \"url\": \"https://news.example.com/ai-hunger\",\n",
    "    \"published_date\": \"2025-02-18\",\n",
    "    \"source\": \"Example News\",\n",
    "    \"author\": \"John Doe\",\n",
    "    \"category\": \"Technology\",\n",
    "    \"enriched_content\": \"AI has made significant advancements... (summary content here)...\\n\\nFact-Checking Data:\\n- Verified by multiple sources\",\n",
    "    \"TF-IDF Outliers\": json.dumps([\"AI\", \"breakthrough\", \"hunger crisis\"]),\n",
    "    \"Grammar Errors\": 2,\n",
    "    \"Sentence Count\": 25,\n",
    "    \"Sentiment Polarity\": 0.7,\n",
    "    \"Sentiment Subjectivity\": 0.4,\n",
    "    \"fact_checking_summary\": \"Verified by multiple sources.\"\n",
    "}\n",
    "\n",
    "# Generate the prompt\n",
    "prompt_text = construct_fact_checking_prompt(example_entry)\n",
    "print(prompt_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEND PROMP TO THE MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02_Llama3\n",
    "to install\n",
    "\n",
    "ollama pull llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: deepseek-r1\n",
      "Response:\n",
      "<think>\n",
      "Alright, so I need to evaluate the credibility of this news article titled \"Breaking News: AI Solves World Hunger.\" Let me go through the process step by step as instructed.\n",
      "\n",
      "First off, looking at the source‚Äîit's from Example News. Hmm, that seems a bit generic and not a reputable news outlet I know of. Usually, I'd expect sources like The New York Times or BBC News for credibility. So, I'm skeptical about this one being reliable.\n",
      "\n",
      "The author is John Doe, but there's no information on his background. If he's just an anonymous author without expertise in AI or global hunger, that raises a red flag. Maybe he doesn't have the necessary credentials to accurately report on such a complex issue.\n",
      "\n",
      "Moving on to the content verification part. The article mentions \"AI has made significant advancements\" but doesn't specify how or provide any credible sources. I know major organizations like the UN or World Bank often tackle issues related to world hunger, so if they've done research in this area, that would add weight to the claim. Without such citations, it's hard to believe the information is accurate.\n",
      "\n",
      "Looking at the linguistic analysis, there are TF-IDF outlier keywords like \"AI,\" \"breakthrough,\" and \"hunger crisis.\" These words might be used to make the article sound more sensational or attention-grabbing, which could indicate that it's trying to catch the reader's interest but at the expense of being fact-based. The grammar issues aren't specified here, but if there are errors, that could mean poor proofreading.\n",
      "\n",
      "The polarity is positive with a 0.7 score, suggesting the article is somewhat optimistic or encouraging. Subjectively, it's rated 0.4 as highly opinionated, which might make sense because it's about AI solving a pressing issue like hunger‚Äîsomething that would likely have strong opinions.\n",
      "\n",
      "Considering bias and sensationalism, the use of \"AI breakthrough\" sounds overly dramatic. It could be trying to alarm readers without providing substantial evidence or balanced information. If other reputable sources aren't reporting similarly, it might indicate a lack of corroborating information from established organizations.\n",
      "\n",
      "In terms of external sources, if Example News isn't citing any credible organizations like the UN, WHO, or FAO, then their report is isolated and lacks support from multiple angles. This could mean that the information is either newly emerging but not widely reported elsewhere or it's a made-up story to attract clicks.\n",
      "\n",
      "Writing quality-wise, without knowing the actual content beyond the summary, I can't assess spelling or grammar errors directly. However, if the article has other issues like missing citations and uses sensational language, these could point towards poor editorial oversight.\n",
      "\n",
      "Putting it all together: The source is unknown and not reputable, the author's credentials are unclear, there are no supporting references from established organizations, and the article uses exaggerated language to make a bold claim. These factors together suggest that while the article claims something significant (AI solving hunger), it lacks sufficient evidence and credibility.\n",
      "</think>\n",
      "\n",
      "**Final Verdict:** False  \n",
      "**Credibility Score:** 20/100  \n",
      "\n",
      "The article, sourced from \"Example News,\" which is not a reputable or well-known news organization, raises immediate skepticism about its reliability. The lack of information on the author's credentials and the absence of credible sources such as established international organizations (e.g., UN, WHO) weakens the credibility of the claim that AI has solved the world hunger crisis. The use of sensational language like \"breakthrough\" and \"AI breakthrough\" contributes to a lack of balance and verifiability. Furthermore, without supporting citations from peer-reviewed research or major reports, the article's assertions are unsubstantiated. \n",
      "\n",
      "**Explanation:**  \n",
      "- **Source Credibility:** Example News is not a reputable source known for accuracy in such claims.\n",
      "- **Content Verification:** The article lacks specific details on AI advancements and credible sources backing its assertion.\n",
      "- **Sensationalist Language:** The use of exaggerated terms suggests a lack of commitment to factual accuracy.\n",
      "- **Bias and Framing:** Without evidence from established organizations, the article appears unsupported.\n",
      "\n",
      "**Conclusion:** The article's claim is unverified, lacks necessary citations, and uses sensational language, rendering it unreliable.\n",
      "\n",
      "\n",
      "Model: llama3\n",
      "Response:\n",
      "### Article Title: Breaking News: AI Solves World Hunger\n",
      "\n",
      "**Step 1 - Source Credibility:**\n",
      "The source, Example News, is not a well-established news organization. The author, John Doe, does not have a clear background or expertise in the field of technology.\n",
      "\n",
      "**Step 2 - Content Verification:**\n",
      "The article claims that \"AI has made significant advancements,\" but provides no specific data or sources to support this claim. Additionally, there is no mention of any credible organizations or research institutions involved in this breakthrough.\n",
      "\n",
      "**Step 3 - Sensationalist Language:**\n",
      "The TF-IDF outlier keywords (\"AI\", \"breakthrough\", and \"hunger crisis\") suggest a sensationalized tone. The sentence count is also relatively high (25), which could indicate an attempt to create a sense of urgency or excitement.\n",
      "\n",
      "**Step 4 - Bias and Framing:**\n",
      "The article's sentiment analysis indicates a neutral polarity (0.7) but a moderately subjective tone (0.4). While the language is not overtly biased, the lack of specific details and credible sources raises concerns about the article's credibility.\n",
      "\n",
      "**Step 5 - External Source Comparison:**\n",
      "Unfortunately, no other reputable news organizations or technology publications have reported on this breakthrough. A search for related articles yielded no results.\n",
      "\n",
      "**Step 6 - Writing Quality:**\n",
      "The linguistic analysis reveals two grammar errors, which may indicate a lack of editorial oversight or attention to detail.\n",
      "\n",
      "**Final Verdict:** Misleading\n",
      "**Credibility Score:** 30/100\n",
      "\n",
      "**Detailed Explanation:** The article's sensationalized language and lack of specific details or credible sources make it difficult to verify the claim that AI has solved world hunger. While the sentiment analysis suggests a neutral tone, the absence of external corroboration and the presence of grammar errors undermine the article's credibility.\n",
      "\n",
      "**Additional Context Needed:** Further information about the organization claiming this breakthrough, as well as peer-reviewed research or official reports supporting their claims, would be necessary to increase confidence in the article's accuracy.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "# Generate the fact-checking prompt\n",
    "prompt_text = construct_fact_checking_prompt(example_entry)\n",
    "\n",
    "# Define the models to use\n",
    "models = [\"deepseek-r1\", \"llama3\"]\n",
    "\n",
    "# Store responses from both models\n",
    "responses = {}\n",
    "\n",
    "for model in models:\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt_text}]\n",
    "        )\n",
    "        responses[model] = response['message']['content']\n",
    "    except Exception as e:\n",
    "        responses[model] = f\"Error processing request: {e}\"\n",
    "\n",
    "# Print the responses\n",
    "for model, content in responses.items():\n",
    "    print(f\"\\nModel: {model}\\nResponse:\\n{content}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUTOMATE PROCESS AND SAVE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: PROMPT_RESULTS\\Prompt_Return_2025-02-20_9.json\n",
      "[\n",
      "    {\n",
      "        \"title\": \"Rock County Jail expansion behind schedule, under budget\",\n",
      "        \"url\": \"https://www.wclo.com/2025/02/19/rock-county-jail-expansion-behind-schedule-under-budget/\",\n",
      "        \"published_date\": \"2025-02-19T23:00:56+00:00\",\n",
      "        \"source\": \"wclo\",\n",
      "        \"author\": \"wclonews\",\n",
      "        \"fact_check_results\": {\n",
      "            \"deepseek-r1\": \"<think>\\nOkay, so I'm trying to figure out if this news article is reliable. Let me read through it carefully.\\n\\nThe title says \\\"Rock County Jail expansion behind schedule, under budget.\\\" Hmm, the date is from 2025-02-19 at 23:00:56, but that's in the future. That seems odd because news articles usually have recent dates, right? Maybe it's a placeholder or something went wrong with the publication time.\\n\\nLooking into the content, it talks about renovations at the sheriff‚Äôs office including a gym, open break area, outdoor courtyard, and heated parking. It mentions moving operations and some inmates into the new building. The budget was $96 million but is still under, which is good news because usually overruns can be a problem.\\n\\nThe summary repeats some of the main points but doesn't add anything new. It ends with a signup for news and offers, which isn't typical in a news article. That might mean it's part of a marketing campaign or something to promote their newsletter rather than providing genuine updates.\\n\\nI also notice mentions like \\\"Fell\\\" without context; I don't know who they are. The links provided include \\\"wclo,\\\" which is the source, and others that seem like press releases or subscription sites for newsletters.\\n\\nThe dates mentioned in the content are from 2024 (summer), but the article was published in early February 2025. That doesn‚Äôt make sense because if they said summer 2024 as a completion date, it's already passed by then. The current end date is moving, which could be possible, but I'm not sure why.\\n\\nThe structure seems off. Typically, news articles are concise and fact-heavy, but this one has more promotional content towards the end with signup links. This might indicate that it's part of a newsletter or marketing piece rather than an official report.\\n\\nI should also consider the source. \\\"wclo\\\" is a local news outlet, so maybe they're using it for their own purposes beyond reporting. But even then, if there are logical inconsistencies like publication dates being in the future and claims about completion that don't align with current timeframes, that raises red flags.\\n\\nIn summary, while some facts are presented, the article has several issues: a suspicious publication date, promotion elements, lack of context for key names, and inconsistent timelines. These make me doubt its reliability as a genuine news source.\\n</think>\\n\\n**Fact-Checking Analysis of the News Article**\\n\\nThe article titled \\\"Rock County Jail Expansion Behind Schedule, Under Budget\\\" published on February 19, 2025, raises several concerns regarding its reliability:\\n\\n1. **Publication Date Anomaly**: The publication date is in the future (February 19, 2025), which is unusual for a news article as it typically reflects current events.\\n\\n2. **Promotional Elements**: The inclusion of signup links and promotional content suggests the article may be part of a newsletter or marketing strategy rather than an official report.\\n\\n3. **Contextual Gaps**: Key individuals like \\\"Fell\\\" lack context, making it difficult to verify their roles within the sheriff‚Äôs office.\\n\\n4. **Timelines Inconsistency**: The mention of completion in summer 2024 contradicts the current publication date and any moving target for the end date, indicating possible inaccuracies.\\n\\n5. **Source Considerations**: While \\\"wclo\\\" is a local news outlet, the article's structure appears tailored more for marketing than factual reporting.\\n\\n**Conclusion**: The article contains inconsistencies and promotional elements that raise doubts about its reliability as an official news source. It may be part of a newsletter or have errors in its publication details.\",\n",
      "            \"llama3\": \"Based on the provided information, I would rate the reliability of this news article as generally high. Here's my fact-checking analysis:\\n\\n1. **Source**: The article is sourced from \\\"wclo\\\", which appears to be a legitimate online news source (the website's URL suggests it's a reputable news organization).\\n2. **Publish date and time**: The article provides a specific publish date and time, which suggests that the information is up-to-date and recent.\\n3. **Specific details**: The article includes concrete details about the renovation project, such as the features mentioned (state-of-the-art gym, large open break area with an outdoor courtyard, heated indoor parking), which adds to its credibility.\\n4. **Timeline**: The article provides a clear timeline of events, including the original expected completion date (summer 2024) and the current estimated completion date (July or July of this year).\\n5. **Quotable sources**: The article quotes an official from the Sheriff's Office (Fell), which adds credibility to the information provided.\\n\\nHowever, I do have some minor concerns:\\n\\n1. **Lack of specificity on delays**: While the article mentions that the project is behind schedule, it doesn't provide a clear explanation for the delay or how much time has passed since the original expected completion date.\\n2. **No mention of third-party verification**: There's no indication that the information was verified by an independent party or organization.\\n\\nOverall, I believe this news article is reliable due to its credible source, specific details, and clear timeline. However, it's always a good idea to consider multiple sources when evaluating any news article.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"Here's the major earnings before the open tomorrow\",\n",
      "        \"url\": \"https://seekingalpha.com/news/4410161-heres-the-major-earnings-before-the-open-tomorrow\",\n",
      "        \"published_date\": \"2025-02-19T23:00:54+00:00\",\n",
      "        \"source\": \"Seeking Alpha\",\n",
      "        \"author\": \"\",\n",
      "        \"fact_check_results\": {\n",
      "            \"deepseek-r1\": \"<think>\\nOkay, so I'm trying to figure out if the news article titled \\\"Here's the Major Earnings Before the Open Tomorrow\\\" from Seeking Alpha is reliable. Let me start by breaking down what the article is saying.\\n\\nFirst off, the title suggests that there are significant earnings announcements coming up before the market opens on a specific day in 2025, which is February 19th at 6:00 PM ET. The article lists several companies with their ticker symbols and mentions some prominent names like Alibaba Group Holding (BABA), Cheniere Energy (LNG), The Southern (SO), Unity Software (U), Walmart (WMT), and others like OTCQX:AAUKF, AEG, AG, etc.\\n\\nLooking at the content, it's clear that this is a list of earnings reports expected before the bell. It mentions these companies as if they're major ones with upcoming earnings. The author, Pranav Ghumatkar, describes himself as an SA News Editor and notes that this should be read in one minute. There's also a \\\"See More\\\" link which probably leads to more details or analysis.\\n\\nNow, considering the sources, it comes from Seeking Alpha, a well-known financial website known for covering market news, analysis, and earnings updates. So on the surface, it seems credible because of the reputable source. However, I should dig deeper.\\n\\nFirstly, dates are important. The article is published on February 19th at 23:00 in UTC, which translates to 6:00 PM ET on the same day. It lists earnings for Thursday, so that would be February 18th? Wait, no, if today is the 19th and the earnings are before the open on the 19th at 6 PM, then perhaps it's referring to tomorrow, which would be February 20th? Or maybe I'm getting confused with the publication date. Let me clarify: The article is published on the morning of the 19th in UTC time, so 6 AM ET would correspond to midnight UTC. Wait no, in the US Eastern Time Zone, if it's 6 PM ET, that's 23:00 UTC. So the publication date is February 19th at 23:00 UTC, which is after the market close of February 19th (which would be at around 5 PM ET). Therefore, it's likely referring to tomorrow's earnings before the open.\\n\\nWait, that makes sense because if today is the 19th and you're publishing an article about earnings tomorrow, that would be on the 20th. So maybe there was a mix-up in dates? Or perhaps I'm misunderstanding. Let me think again: The article says it's published on 2025-02-19T23:00:54+00:00, which is February 20th at approximately 10:54 PM in London time? Wait no, actually, the publication date is 2025-02-19, so that's the 19th of February. The time is 23:00:54+00:00, which would be midnight plus a few seconds on the 20th in many timezone conversions. So perhaps it's trying to indicate the next day.\\n\\nBut regardless, whether it's for today or tomorrow, the article provides a list of companies expected to report earnings before the market opens. Now, is this reliable?\\n\\nSeeking Alpha generally provides timely earnings alerts, but I should verify if these specific companies are indeed scheduled to report earnings on that date. Let me think about each company mentioned:\\n\\n- Alibaba Group Holding (BABA): A major tech company; they do have earnings releases regularly. It's plausible they might report on a Thursday.\\n- Cheniere Energy (LNG): An energy company, earnings could be relevant given their market position.\\n- The Southern (SO): This is a stock ticker symbol I'm less familiar with. Wait, SO might refer to Suning Group in China? Or another entity. Alternatively, maybe it's misbranded or not a well-known company; if it's a smaller firm, there might be doubts about the reliability of their earnings report.\\n- Unity Software (U): A tech software company, likely to have earnings releases.\\n- Walmart (WMT): A major consumer goods company, definitely has earnings reports regularly.\\n\\nOther tickers like OTCQX:AAUKF seem less familiar. OTCQX is a Pink Sheets market, so these are smaller or penny stocks. Earnings for such companies might be more volatile and less reliable in terms of meaningful financials.\\n\\nThe format also includes an analysis link where the user can see more details about each earnings report. This adds credibility because it provides access to further information rather than just listing them.\\n\\nHowever, considering that this is a news article from 2025, which is five years into the future, there's a possibility of inaccuracies due to economic changes, market dynamics shifts, or other unforeseen events affecting these companies. But since it's published in 2025, I can't verify the current status.\\n\\nAnother point is whether the publication date and time align with the earnings release times. The article is published on February 19th at 6 PM ET, which would be after the market has closed for the day (which usually closes around 4:30-5 PM ET). Therefore, it's likely intended to provide an evening or pre-open analysis.\\n\\nI should also consider if there are any known factors that might cause discrepancies between when earnings announcements are listed and when they actually occur. Sometimes, companies announce their fiscal quarters earlier than expected due to economic calendar events like Federal Reserve meetings or earnings beats/misses affecting investor sentiment.\\n\\nAdditionally, the article doesn't provide specific dates for each company's earnings release beyond them being before Thursday's open. So I can't confirm exact times or whether these companies are indeed releasing on that day as listed.\\n\\nThe inclusion of a disclaimer from the SA News Editor is a bit concerning because it suggests that this might be an automated or routine update, possibly without in-depth analysis. While this isn't necessarily bad, some readers might expect more detailed insights beyond just the list and link to further info.\\n\\nMoreover, since the article doesn't provide any context about why these specific companies are expected to have earnings before the open, it's hard to assess their relevance or significance compared to others on the same day.\\n\\nIn terms of reliability, Seekings Alpha is generally considered a reliable source for financial news. However, relying solely on such sources without cross-checking with other reputable platforms (like Yahoo Finance, Bloomberg, or Morningstar) could leave some doubts because each platform might have different fiscal calendars and release times.\\n\\nI should also consider if the article contains any biases or potential conflicts of interest. The author is a SA News Editor, but there's no indication that he has a personal stake in these companies, so bias isn't an issue here.\\n\\nAnother aspect is whether the list includes all major sectors represented on earnings day. For example, if this article only lists tech and energy companies but misses out on consumer goods or other sectors, it might be incomplete.\\n\\nIn conclusion, while the article from Seeking Alpha provides a list of expected earnings before the market opens for a specific date, its reliability could be affected by factors such as publication timing relative to actual earnings releases, the nature of the companies listed (especially smaller ones in penny stocks), and the absence of detailed analysis or cross-verification. However, given the reputable source, it's generally credible but should be corroborated with other information.\\n</think>\\n\\nThe article from Seeking Alpha titled \\\"Here's the Major Earnings Before the Open Tomorrow\\\" published on February 19, 2025, at 6 PM ET provides a list of companies expected to report earnings before the market opens. Here is a summary of the analysis:\\n\\n### Key Considerations for Reliability:\\n1. **Source Credibility**: Seeking Alpha is generally reliable, but being an automated update without in-depth analysis might be a limitation.\\n2. **Publication Timing**: Published after market close on February 19, it's intended as evening or pre-market analysis.\\n3. **Company Nature**:\\n   - Major companies like Alibaba (BABA) and Walmart (WMT) are likely reliable due to their regular earnings reports.\\n   - Smaller companies in penny stocks (e.g., OTCQX:AAUKF) might have less stable financials, affecting reliability.\\n4. **Economic Calendar Considerations**: Companies may release earnings earlier than expected due to factors like Federal Reserve meetings or investor sentiment.\\n\\n### Conclusion:\\nThe article is credible as it comes from a reputable source and provides access for further details. However, it should be cross-checked with other platforms for accuracy, especially considering the publication in 2025 where economic conditions might differ. The list may not cover all sectors fully, adding potential incompleteness.\\n\\nIn summary, while the article is generally reliable, readers are advised to corroborate it with additional sources for a comprehensive understanding.\",\n",
      "            \"llama3\": \"I've analyzed the news article and performed a fact-checking analysis to determine its reliability. Here are my findings:\\n\\n**Reliability Assessment:**\\n\\n1. **Source:** The article is from Seeking Alpha, a well-established financial news website that provides expert insights, market analysis, and news on various stocks and industries.\\n2. **Content:** The article appears to be factual, listing major earnings releases expected before the open tomorrow (Thursday). It does not contain any sensational or promotional language, which suggests an objective reporting style.\\n3. **Information quality:** The article provides a comprehensive list of companies releasing their earnings reports, including notable stocks like Alibaba Group Holding (BABA) and Walmart (WMT).\\n4. **Author credibility:** Pranav Ghumatkar is the SA News Editor, implying that he has experience in financial journalism and likely has a deep understanding of the market and its trends.\\n\\n**Fact-Checking Analysis:**\\n\\n1. **Accuracy:** The article appears to be accurate in listing major earnings releases expected before the open tomorrow.\\n2. **Sources:** Seeking Alpha likely relies on reputable sources such as Bloomberg, Reuters, or company press releases for its information.\\n3. **Objectivity:** The article does not contain any biased language or promote specific stocks or industries.\\n\\n**Limitations:**\\n\\n1. **Lack of context:** The article provides a list of earnings releases without offering much context about the companies' performances or market expectations.\\n2. **Limited analysis:** There is no in-depth analysis or commentary on the expected earnings or their potential impact on the market.\\n\\n**Conclusion:**\\nBased on my analysis, I conclude that this news article is reliable. Seeking Alpha has a good reputation for providing accurate and objective financial news, and Pranav Ghumatkar's credentials as an SA News Editor suggest he is knowledgeable about the markets and industries. While the article lacks context and in-depth analysis, its primary function is to provide a list of expected earnings releases, which it does accurately.\\n\\nRating: Reliable (4/5)\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"Salvation Army Bintulu, kapitan step up to aid the homeless\",\n",
      "        \"url\": \"https://www.theborneopost.com/2025/02/20/salvation-army-bintulu-kapitan-step-up-to-aid-the-homeless/\",\n",
      "        \"published_date\": \"2025-02-19T23:00:53+00:00\",\n",
      "        \"source\": \"theborneopost\",\n",
      "        \"author\": \"Yunus Yussop\",\n",
      "        \"fact_check_results\": {\n",
      "            \"deepseek-r1\": \"<think>\\nAlright, so I need to figure out if the given news article is reliable. Let me start by reading through it carefully. The title says \\\"Salvation Army Bintulu, kapitan step up to aid the homeless,\\\" and it's from \\\"theborneopost\\\" published on February 19, 2025.\\n\\nFirst, I'll look at the content. It talks about a group of homeless individuals in Bintulu due to various social issues like broken families or physical illnesses. The Salvation Army is helping them with food, clothing, shelters, medical aid, and psychological counseling. They mention Kapitan Dr Simon Hong's efforts.\\n\\nThe summary is similar but shorter, just restating the main points. Both the content and summary are quite detailed about the causes of homelessness and the interventions by the Salvation Army.\\n\\nNow, considering reliability: Fact-checking usually involves verifying information against known sources or databases. But since I can't access external databases right now, I'll have to rely on what I know about the Salvation Army in Bintulu and Dr. Simon Hong's role as Kapitan there.\\n\\nThe name \\\"Bintulu\\\" seems like a community in Sabah, Malaysia, given the source's name (\\\"theborneopost,\\\" which might be associated with Sabah). The Salvation Army is a well-known international organization that works in various communities globally, so it makes sense they would have a presence in Bintulu.\\n\\nDr. Simon Hong being Kapitan suggests he's a local leader or community leader within the Salvation Army there. That seems plausible since the organization often collaborates with local leaders for outreach programs.\\n\\nThe article mentions resource shortages as a bottleneck. I know that many NGOs face such issues due to high operational costs and lack of funding, so this isn't an uncommon issue. They are calling on the public to donate or volunteer, which is typical for organizations seeking support.\\n\\nHowever, without specific data points from credible sources about this particular article's accuracy, it's hard to verify specifics like exact causes, the number of homeless individuals helped, or financial details. But since the information structure and references seem logical based on known operations, I can tentatively say it's reliable.\\n\\nI should note that while there are no immediate red flags, reliability without verification is a bit uncertain. It might be more accurate to report this as somewhat reliable but without definitive proof.\\n</think>\\n\\nThe news article appears to be reasonably reliable due to the following reasons:\\n\\n1. **Source Credibility**: The article is sourced from \\\"theborneopost,\\\" which, while not immediately recognizable, aligns with Bintulu in Sabah, Malaysia, a plausible location for an international organization like the Salvation Army.\\n\\n2. **Organizational Affiliation**: The Salvation Army is a well-established international NGO known for its work in communities globally. Their presence in Bintulu and Kapitan Dr Simon Hong's role as a local leader are consistent with typical collaborations between NGOs and local leaders.\\n\\n3. **Program Structure**: The article details specific interventions by the Salvation Army, including food, clothing, shelters, medical aid, and psychological counseling, which are standard practices for such organizations aiming to assist the homeless.\\n\\n4. **Resource Shortages**: The mention of resource limitations is a common challenge faced by NGOs, indicating that this issue is plausible and not an anomaly.\\n\\n5. **Call for Support**: Encouraging public donations or volunteer services aligns with the typical strategies used by NGOs to garner support and sustain their operations.\\n\\nWhile no definitive verification was possible without external sources, these factors suggest the article is reliable, though it's important to note that without further evidence, this conclusion remains tentative.\",\n",
      "            \"llama3\": \"Fact-Checking Analysis:\\n\\nOverall Reliability: 8/10\\n\\nReasons for reliability:\\n\\n1. The article quotes a Corps officer, Captain Daniel Lim, who is likely an expert in the Salvation Army's activities and mission.\\n2. The article provides specific examples of the challenges faced by homeless individuals, which are consistent with common societal issues.\\n3. The article highlights the Salvation Army's efforts to provide not just material support but also psychological counseling and medical aid, which aligns with their stated mission.\\n\\nReasons for caution:\\n\\n1. Lack of concrete data or statistics on homelessness in Bintulu or Malaysia as a whole, making it difficult to quantify the extent of the issue.\\n2. No mention of any specific programs or initiatives undertaken by the Salvation Army or Kapitan Dr. Simon Hong that are not already well-known facts about their work.\\n3. The article relies heavily on anecdotal evidence and quotes from individuals involved in the Salvation Army's activities, which may be subject to personal biases.\\n\\nSuggestions for improvement:\\n\\n1. Provide more concrete data and statistics on homelessness in Bintulu or Malaysia as a whole to give readers a better understanding of the scope of the issue.\\n2. Include specific examples or case studies of successful programs or initiatives undertaken by the Salvation Army or Kapitan Dr. Simon Hong that demonstrate their effectiveness.\\n3. Consider including quotes from other stakeholders, such as local government officials or experts in the field of homelessness, to provide a more well-rounded perspective.\\n\\nOverall, while this article is generally reliable, it could benefit from additional context and evidence to support its claims.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"Tabung Baitulmal Sarawak introduces zakat fitrah payment via QR code\",\n",
      "        \"url\": \"https://www.theborneopost.com/2025/02/20/tabung-baitulmal-sarawak-introduces-zakat-fitrah-payment-via-qr-code/\",\n",
      "        \"published_date\": \"2025-02-19T23:00:49+00:00\",\n",
      "        \"source\": \"theborneopost\",\n",
      "        \"author\": \"Jude Toyat\",\n",
      "        \"fact_check_results\": {\n",
      "            \"deepseek-r1\": \"<think>\\nOkay, so I need to figure out if the news article about TBS introducing Zakat Fitrah payments via QR codes is reliable. Let me start by going through the article step by step.\\n\\nFirst, the title mentions that TBS has introduced this new payment method as an alternative to cash. They're working with BIMB, which I think stands for Bank Islam Malaysia Berhad. The initiative is meant to make Zakat Fitrah transactions safer and more controlled.\\n\\nLooking at the content, it starts by quoting Abang Mohd Shibli from Kuching before the event. He mentions that they'll be piloting this QR code system in Kuching during Ramadan this year and then expanding across Sarawak next year. That makes sense because Ramadan is a time when people are away from home, so digital payments might be easier to handle.\\n\\nHe talks about the collaboration with BIMB aligning with the digital era, which seems reasonable since many people use QR codes now. He says it's to simplify the process and ensure smoother transactions for both TBS and amil (the Zakat collectors). I'm not sure how much they actually do know about QR codes; maybe they're just adopting because everyone else is doing it.\\n\\nHe also mentions that they're training amil on using QR codes, which is good. The fact that they can't expand yet due to logistical challenges like \\\"accessibility\\\" and \\\"logistical problems\\\" sounds plausible‚Äîmaybe there's a shortage of staff or resources needed to roll it out everywhere.\\n\\nThe estimated 200 amil in Kuching who are tech-savvy seems like a reasonable number. The part about appointing individuals comfortable with mobile phones is fair, as tech skills might vary among mosque and surau committees.\\n\\nHe reassures that QR codes don't affect Shariah rulings, which I think is correct because it's just a payment method. He also says the Zakat fitrah rate hasn't been finalized yet but will be discussed at the Islamic Council level, so there's uncertainty about exact numbers, but they expect it won't change much.\\n\\nThe article ends by noting that this isn't about changing the rate but ensuring proper distribution and accuracy of information through TBS. That makes sense as a clarification to avoid any confusion.\\n\\nNow, for fact-checking: The date is February 20, 2025, which seems recent enough. The publication source is Borneo Post Online. I don't have access to check the actual publication's current content, but assuming it's updated regularly, that's fine.\\n\\nThe article doesn't have any red flags like false information about rates or government approvals missing. It mentions collaboration with a known bank and a reasonable time frame for expansion. The language is formal but clear.\\n\\nPotential issues: I don't know if TBS actually rolled out the QR code in Kuching yet since the date is 2025, so maybe it's new information as of that date. Also, the exact rate details might not be final, which could affect reliability for someone planning to collect Zakat Fitrah.\\n\\nOverall, considering all factors, I think the article is generally reliable but should be checked for any updates or corrections from official sources.\\n</think>\\n\\nThe news article about Tabung Baitulmal Sarawak (TBS) introducing Zakat Fitrah payments via QR codes appears to be reliable based on several key points:\\n\\n1. **Source and Date**: The article is published by Borneo Post Online, a reputable source as of 2025. The date of publication is February 20, 2025.\\n\\n2. **Collaboration Details**: It mentions collaboration with Bank Islam Malaysia Berhad (BIMB), a recognized financial institution, which adds credibility to the initiative.\\n\\n3. **Purpose and Scope**: The article clearly outlines that the QR code system aims to enhance safety and control in Zakat Fitrah transactions. It plans a phased rollout starting in Kuching during Ramadan, followed by expansion across Sarawak next year, acknowledging logistical challenges as potential barriers.\\n\\n4. **Amil Training**: It highlights efforts to train Zakat collectors (amil) on using QR codes, emphasizing the importance of digital literacy among them.\\n\\n5. **Uncertainty Clarified**: The article clarifies that while the exact Zakat fitrah rate is under discussion and may not change much from previous levels, it does not affect Shariah rulings, focusing instead on accurate information distribution through TBS.\\n\\n6. **Language and Tone**: The language used is formal yet clear, without any apparent misinformation or biases.\\n\\nHowever, potential concerns include the article's age (as of 2025) regarding specific details like the exact rate, which may not reflect current developments. Additionally, there's no mention of official approvals or government consent, though this isn't always explicitly required for such news.\\n\\nOverall, while the article is credible and well-structured, it should be interpreted with consideration of its age and any potential updates from official sources.\",\n",
      "            \"llama3\": \"Based on the article, I would rate its reliability as 7 out of 10. Here's my fact-checking analysis:\\n\\n**Verifiable facts:**\\n\\n1. The article quotes Abang Mohd Shibli, TBS general manager, accurately reporting his statements and quotes.\\n2. Bank Islam Malaysia Berhad (BIMB) is a real bank in Malaysia, and it is possible that they collaborated with Tabung Baitulmal Sarawak (TBS).\\n3. Zakat Fitrah is an actual Islamic practice where Muslims pay a portion of their excess wealth to help those in need during Ramadan.\\n4. Kuching is a city in Sarawak, Malaysia.\\n\\n**Unverifiable or potentially biased claims:**\\n\\n1. The article states that the QR code payment system will be piloted in the Kuching Division during this year's Ramadan and expanded across Sarawak next year. There is no concrete evidence to support this claim.\\n2. Abang Mohd Shibli estimates around 200 amil in Kuching will adopt the QR code payment method, but this number is not verified or sourced from any credible source.\\n3. The article reports that TBS general manager reassured that the use of QR codes does not pose any Shariah concerns, but this claim requires further verification and expertise in Islamic law.\\n\\n**Potential biases:**\\n\\n1. The article appears to be promotional in nature, as it highlights Tabung Baitulmal Sarawak's (TBS) initiative without providing a balanced perspective or critical analysis.\\n2. The lack of concrete evidence and verifiable sources for some claims raises concerns about the reliability of the information.\\n\\n**Recommendations:**\\n\\n1. Verify the specific details reported in the article, such as the number of amil adopting the QR code payment method and the timeline for expansion across Sarawak.\\n2. Consult with experts in Islamic law to assess the Shariah concerns surrounding the use of QR codes for zakat transactions.\\n3. Consider including a balanced perspective or critical analysis to provide a more comprehensive understanding of the initiative.\\n\\nOverall, while the article appears to be well-intentioned and accurate in its reporting of quotes and basic facts, it requires further verification and critical evaluation to determine its reliability.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"New evidence alters plan for inquest into three custody deaths\",\n",
      "        \"url\": \"https://lfpress.com/news/local-news/new-evidence-alters-plan-for-inquest-into-three-custody-deaths\",\n",
      "        \"published_date\": \"2025-02-19T23:00:46+00:00\",\n",
      "        \"source\": \"lfpress\",\n",
      "        \"author\": \"Randy Richmond\",\n",
      "        \"fact_check_results\": {\n",
      "            \"deepseek-r1\": \"<think>\\nOkay, I need to analyze whether the provided news article is reliable. Let me start by reading through the content carefully.\\n\\nThe article reports that new evidence has delayed the coroner's inquest into Amanda Bolt's 2019 death while another two related deaths are still being investigated. The key points mentioned include her arrest details, medical issues, and how she died after being re-arrested.\\n\\nLooking at the structure of the article, it starts with a catchy title that suggests an important update, followed by a date and source information. Then there's content about the delay in the inquest due to new evidence. The author mentions Chris Bolt, his brother, explaining that further investigation is needed based on new details. There's also information about the Special Investigations Unit (SIU) involved in previous cases, including the SIU's findings regarding medication and medical distress.\\n\\nHowever, I notice a few red flags. First, the article ends abruptly after mentioning two other deaths by Fabian Hart and Christopher Campbell without providing complete details or conclusions about their investigations. This leaves readers with incomplete information. Additionally, there are repeated calls to register or sign in for access to the full content, which is a common tactic to encourage premium subscriptions rather than relying on free versions.\\n\\nThe article includes some internal police reports but doesn't provide external sources or independent verification of these findings. The lack of context about why the new evidence specifically affects only Amanda Bolt's case makes it harder to assess the reliability conclusively. \\n\\nMoreover, there are placeholders for contact information and a note about the real estate newsletter, which might be intended as an additional offer rather than part of the article's content.\\n\\nConsidering these factors‚Äîrepeated calls to subscribe, abrupt endings without full context, lack of external verification, and incomplete details‚Äîthe article may not be entirely reliable. It could be seen as sensational or incomplete, lacking the thoroughness one would expect in a news piece about such serious incidents.\\n</think>\\n\\nThe analysis of the provided news article reveals several concerns regarding its reliability:\\n\\n1. **Incomplete Information**: The article abruptly ends after mentioning two other deaths without providing full context or outcomes, leaving readers with incomplete information.\\n\\n2. **Repeated Encouragement to Subscribe**: The inclusion of subscription calls and promotional content suggests a bias towards monetization rather than providing factual news.\\n\\n3. **Lack of External Verification**: The absence of external sources or independent verification for the findings complicates assessing the credibility of the information.\\n\\n4. **Internal Reports Without Context**: While internal police reports are mentioned, they lack context from external perspectives, raising questions about their thoroughness and reliability.\\n\\n5. **Placeholders and Redundant Content**: Repetitive contact information and placeholders for a real estate newsletter may serve promotional purposes rather than enhancing content quality.\\n\\nConsidering these factors, the article appears to be incomplete and potentially biased, which raises doubts about its reliability as a source of accurate information on serious incidents involving Amanda Bolt's death.\",\n",
      "            \"llama3\": \"Based on my analysis, I consider this news article to be generally reliable. Here's why:\\n\\n1. **Source credibility**: The article is from a reputable source, the London Free Press (lfpress), which has been in operation since 1847 and is part of Postmedia Network Inc., a well-established media company.\\n2. **Accurate information**: The article presents factual information about the case, including quotes from relevant parties (Amanda Bolt's brother Chris Bolt) and references to specific events, dates, and reports (e.g., internal police report presented to the London police services board in 2022).\\n3. **Clear reporting**: The article clearly explains the situation, providing context for readers who may not be familiar with the case.\\n4. **Transparency**: The article does not contain any obvious bias or attempts to sensationalize the story.\\n\\nHowever, there are a few areas where I would like to see more transparency and clarity:\\n\\n1. **Lack of specific details on new evidence**: The article mentions that \\\"new evidence has come to light\\\" but does not provide any specifics about what this evidence is or how it relates to Amanda Bolt's death.\\n2. **No quotes from investigating authorities**: While the brother Chris Bolt provides insight, there are no quotes from the investigators (e.g., Ontario's Special Investigations Unit) or other relevant parties that could offer additional context.\\n\\nOverall, I believe the article is reliable and presents a balanced view of the situation. However, readers may benefit from more specific details on the new evidence and quotes from investigating authorities to gain a deeper understanding of the case.\"\n",
      "        }\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import ollama\n",
    "import chromadb\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def fetch_entries_from_chromadb(collection_name=\"news_articles\", max_entries=5):\n",
    "    \"\"\" Fetches the latest enriched entries from ChromaDB. \"\"\"\n",
    "    try:\n",
    "        client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "        collection = client.get_collection(name=collection_name)\n",
    "        results = collection.get(include=[\"metadatas\", \"documents\"], limit=max_entries)\n",
    "\n",
    "        entries = []\n",
    "        for i in range(len(results[\"documents\"])):\n",
    "            entry = {\n",
    "                \"title\": results[\"metadatas\"][i].get(\"title\", \"Unknown Title\"),\n",
    "                \"url\": results[\"metadatas\"][i].get(\"url\", \"Unknown URL\"),\n",
    "                \"published_date\": results[\"metadatas\"][i].get(\"published_date\", \"Unknown Date\"),\n",
    "                \"source\": results[\"metadatas\"][i].get(\"source\", \"Unknown Source\"),\n",
    "                \"author\": results[\"metadatas\"][i].get(\"author\", \"Unknown Author\"),\n",
    "                \"enriched_content\": results[\"documents\"][i]\n",
    "            }\n",
    "            entries.append(entry)\n",
    "        return entries\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data from ChromaDB: {e}\")\n",
    "        return []\n",
    "\n",
    "def construct_fact_checking_prompt(entry):\n",
    "    \"\"\" Constructs a fact-checking prompt for the LLM. \"\"\"\n",
    "    return f\"\"\"\n",
    "    Analyze the following news article:\n",
    "\n",
    "    Title: {entry['title']}\n",
    "    Source: {entry['source']}\n",
    "    Published: {entry['published_date']}\n",
    "    Content: {entry['enriched_content']}\n",
    "\n",
    "    Is this news article reliable? Provide a fact-checking analysis.\n",
    "    \"\"\"\n",
    "\n",
    "def get_unique_filename(base_path=\"PROMPT_RESULTS\"):\n",
    "    \"\"\" Generates a unique filename for storing responses. \"\"\"\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "    date_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    file_number = 1\n",
    "\n",
    "    while True:\n",
    "        filename = f\"Prompt_Return_{date_str}_{file_number}.json\"\n",
    "        full_path = os.path.join(base_path, filename)\n",
    "        if not os.path.exists(full_path):\n",
    "            return full_path\n",
    "        file_number += 1\n",
    "\n",
    "def analyze_multiple_articles(chroma_entries, models=[\"deepseek-r1\", \"llama3\"]):\n",
    "    \"\"\"\n",
    "    Sends multiple articles to specified LLM models for analysis and ensures results are structured per model.\n",
    "    \"\"\"\n",
    "    responses = []\n",
    "\n",
    "    for entry in chroma_entries:\n",
    "        prompt_text = construct_fact_checking_prompt(entry)\n",
    "        fact_check_results = {}\n",
    "\n",
    "        for model in models:\n",
    "            try:\n",
    "                response = ollama.chat(\n",
    "                    model=model,\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt_text}]\n",
    "                )\n",
    "                fact_check_results[model] = response['message']['content']\n",
    "            except Exception as e:\n",
    "                fact_check_results[model] = f\"Error processing request: {e}\"\n",
    "\n",
    "        responses.append({\n",
    "            \"title\": entry.get(\"title\", \"Unknown Title\"),\n",
    "            \"url\": entry.get(\"url\", \"Unknown URL\"),\n",
    "            \"published_date\": entry.get(\"published_date\", \"Unknown Date\"),\n",
    "            \"source\": entry.get(\"source\", \"Unknown Source\"),\n",
    "            \"author\": entry.get(\"author\", \"Unknown Author\"),\n",
    "            \"fact_check_results\": fact_check_results  # Aqu√≠ se guardan los resultados por modelo\n",
    "        })\n",
    "\n",
    "    # Guardar resultados en JSON\n",
    "    output_file = get_unique_filename()\n",
    "    try:\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "            json.dump(responses, file, indent=4, ensure_ascii=False)\n",
    "        print(f\"Results saved to: {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving results: {e}\")\n",
    "\n",
    "    return responses\n",
    "\n",
    "# ** Ejecutar el an√°lisis **\n",
    "chroma_entries = fetch_entries_from_chromadb(max_entries=5)\n",
    "if chroma_entries:\n",
    "    results = analyze_multiple_articles(chroma_entries)\n",
    "    print(json.dumps(results, indent=4, ensure_ascii=False))\n",
    "else:\n",
    "    print(\"No data retrieved from ChromaDB.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Comparison of Models: DeepSeek R1 Model vs. Combined Model**  \n",
    "\n",
    "The two JSON files contain fact-checking results generated by LLMs on various news articles.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Key Differences**  \n",
    "\n",
    "#### **1. Evaluation Sources**  \n",
    "- The **DeepSeek R1 Model** file contains analyses using **only DeepSeek R1**.  \n",
    "- The **Combined Model** file includes responses from **both DeepSeek R1 and LLaMA**.  \n",
    "\n",
    "#### **2. Structure and Depth of Analysis**  \n",
    "- Both files include detailed reasoning before giving a conclusion, following a step-by-step `<think>` format.  \n",
    "- The **Combined Model** file features **longer and more reflective analyses**, likely due to the combination of models.  \n",
    "\n",
    "#### **3. Decision-Making Approach**  \n",
    "- The **DeepSeek R1 Model** generally **confirms plausibility** based on logical structure and available content.  \n",
    "- The **Combined Model** **adds more nuance** by questioning source credibility and identifying issues such as `404` or `403` errors on the cited pages.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Differences in Specific Evaluations**  \n",
    "\n",
    "| **Article Title** | **DeepSeek R1 Model** | **Combined Model** |\n",
    "|-------------------|----------------------|--------------------|\n",
    "| **\"Presidents and Morality\"** | Recognizes The Conversation as a credible source with expert opinions but acknowledges that it‚Äôs not peer-reviewed. | More thorough historical fact-checking, questioning specific presidential ranking changes over time. |\n",
    "| **\"Prince and Princess of Wales‚Äô Mustique Villa\"** | Skeptical due to an unknown source and a `404` error on the page. | Provides a more structured analysis of the plausibility of the price and property details. |\n",
    "| **\"Scottish Museum Transformation\"** | Questions reliability due to the lack of corroboration from major media. | Identifies issues with date formatting and evaluates whether the funding claim is plausible. |\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**  \n",
    "- **The Combined Model (DeepSeek + LLaMA) provides a stronger and more detailed analysis.**  \n",
    "- Combining models **improves fact-checking accuracy**, as LLaMA appears to enhance **historical verification and structural analysis** of the news articles.  \n",
    "- If the goal is to **improve precision**, **continuing with the combined model approach** seems like the best option.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
